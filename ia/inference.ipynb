{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512, 512]), torch.Size([1, 1, 512, 512]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from zipfile import ZipFile\n",
    "\n",
    "INPLACE=False \n",
    "CONVPAD='zeros'\n",
    "\n",
    "def pt_get_activation(activation) -> nn.Module:\n",
    "    \"\"\" Retorna un modulo de activacion por nombre.\n",
    "    Retorna None si el nombre no coincide \"\"\"\n",
    "    if(activation is None): return None\n",
    "    elif isinstance(activation,nn.Module): return activation\n",
    "    elif(activation=='relu'): return nn.ReLU(inplace=INPLACE)\n",
    "    elif(activation=='elu'): return nn.ELU(inplace=INPLACE)\n",
    "    elif(activation=='leakyrelu'): return nn.LeakyReLU(inplace=INPLACE)\n",
    "    elif(activation=='sigmoid'): return nn.Sigmoid()\n",
    "    elif(activation=='logsigmoid'): return nn.LogSigmoid()\n",
    "    elif(activation=='softmax'): return nn.Softmax(dim=1)\n",
    "    elif(activation=='softmin'): return nn.Softmin(dim=1)\n",
    "    elif(activation=='logsoftmax'): return nn.LogSoftmax(dim=1)\n",
    "    elif(activation=='prelu'): return nn.PReLU()\n",
    "    elif(activation=='relu6'): return nn.ReLU6(inplace=INPLACE)\n",
    "    elif(activation=='rrelu'): return nn.RReLU(inplace=INPLACE)\n",
    "    elif(activation=='selu'): return nn.SELU(inplace=INPLACE)\n",
    "    elif(activation=='celu'): return nn.CELU(inplace=INPLACE)\n",
    "    elif(activation=='gelu'): return nn.GELU(approximate='tanh')\n",
    "    elif(activation=='silu'): return nn.SiLU(inplace=INPLACE)\n",
    "    elif(activation=='mish'): return nn.Mish(inplace=INPLACE)\n",
    "    elif(activation=='softplus'): return nn.Softplus()\n",
    "    elif(activation=='softsign'): return nn.Softsign()\n",
    "    elif(activation=='softshrink'): return nn.Softshrink()\n",
    "    elif(activation=='tanh'): return nn.Tanh()\n",
    "    return None\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\" Convolution + Activation \"\"\"\n",
    "        \n",
    "    def __init__(self, ic:int, oc:int, k=3, s=1, p=1, bias=True, activation=None, scale=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ic, oc, kernel_size=k, stride=s, padding=p, bias=bias, padding_mode=CONVPAD)\n",
    "        self.activation = pt_get_activation(activation)\n",
    "        self.scale = scale\n",
    "        self.residual = residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        x = self.conv(x)\n",
    "        if(self.activation is not None): x = self.activation(x)\n",
    "        if(self.scale is not None): x = self.scale(x)\n",
    "        if(self.residual): x = x0 + x\n",
    "        return x\n",
    "    \n",
    "class ResID07(nn.Module):\n",
    "    \"\"\" Bloque residual bn+act+conv+bn+act+conv con ajuste de dimensiones espaciales y semanticas \"\"\" \n",
    "    def __init__(self, ic:int, oc:int, activation='relu', dropout=0.0, expansion=1, resample=None):\n",
    "        super().__init__()\n",
    "        mc = int(ic*expansion)\n",
    "        self.norm1 = torch.nn.BatchNorm2d(ic, momentum=0.01)\n",
    "        self.act1  = pt_get_activation(activation) \n",
    "        self.conv1 = Conv(ic,mc,k=3,s=1,p=1)\n",
    "        \n",
    "        self.resample = resample\n",
    "        \n",
    "        self.norm2 = torch.nn.BatchNorm2d(mc, momentum=0.01)\n",
    "        self.act2  = pt_get_activation(activation)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout>0.0 else None\n",
    "        self.conv2 = Conv(mc,oc,k=3,s=1,p=1)\n",
    "        \n",
    "        self.conv3 = Conv(ic,oc,k=1,s=1,p=0) if ic!=oc else None\n",
    "        \n",
    "    def forward(self, x, emb=None):\n",
    "        x0 = x\n",
    "        if(self.norm1 is not None): x = self.norm1(x)\n",
    "        if(self.act1  is not None): x = self.act1(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        if(emb is not None): x = x+emb\n",
    "        \n",
    "        if(self.resample is not None):\n",
    "            x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
    "            x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
    "        \n",
    "        if(self.norm2   is not None): x = self.norm2(x)\n",
    "        if(self.act2    is not None): x = self.act2(x)\n",
    "        if(self.dropout is not None): x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        if self.conv3 is not None: x0 = self.conv3(x0) #(b,oc,h,w) Ajusta los canales para que sean iguales.\n",
    "        \n",
    "        return x0 + x\n",
    "    \n",
    "class ResID07N(nn.Module):\n",
    "    \"\"\" N bloques ResID07 \"\"\"\n",
    "    def __init__(self, ic:int, n=2, activation='relu', dropout=0.0, expansion=2):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for _ in range(n): self.layers.append(ResID07(ic,ic, activation=activation, dropout=dropout, expansion=expansion))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class UNetSam(nn.Module):\n",
    "    \"\"\" UNET\n",
    "    La primera seccion aplica ResID07 con resample=0.5 varias veces para reducir  la resolucion y aumentar la cantidad de filtros, hasta llegar a la maxima cantidad de filtros.\n",
    "    La segunda seccion aplica ResID07 con resample=2.0 varias veces para aumentar la resolucion y reducir  la cantidad de filtros.\n",
    "    Agrega enlaces entre la primera y segunda seccion.\n",
    "    Retorna una lista 'y' con todas las salidas de cada nivel, siendo y[0] la entrada e y[-1] la ultima salida\n",
    "    activation2: Activacion de SAM: sigmoid, softmax8, softmax16, softmax32\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filters=(1,16,32,64,128,256,128,64,32,16), n=1, activation='relu', dropout=0.0, expansion=1):\n",
    "        super().__init__()\n",
    "        c = len(filters) #Total de filtros\n",
    "        j = np.argmax(filters) #Indice de la mayor cantidad de filtros (Parte mas ancha de la UNet)\n",
    "        \n",
    "        self.convs = nn.ModuleList() #Lista de modulos ConvBnAct\n",
    "        self.convs_res = nn.ModuleList() #Lista de modulos ResID01N\n",
    "\n",
    "        for i in range(1,j+1):\n",
    "            f1 = filters[i-1]\n",
    "            f2 = filters[i]\n",
    "            self.convs.append( ResID07(f1,f2,resample=0.5,activation=activation, dropout=dropout, expansion=expansion))\n",
    "            module = ResID07N(f2,n=n,activation=activation, dropout=dropout, expansion=expansion)\n",
    "            self.convs_res.append(module)\n",
    "            \n",
    "        self.convts = nn.ModuleList() #Lista de modulos ConvTBnAct (Convolucion Transpuesta)\n",
    "        self.convts_res = nn.ModuleList() #Lista de modulos ResID01N\n",
    "        self.links = nn.ModuleList() #Lista de modulos ConvBnAct para enlazar la primera seccion con la segunda\n",
    "        for i in range(j+1,c):\n",
    "            f1 = filters[i-1]\n",
    "            f2 = filters[i]\n",
    "            self.convts.append(ResID07(f1,f2,resample=2,activation=activation, dropout=dropout, expansion=expansion))\n",
    "            module = ResID07N(f2,n=n,activation=activation, dropout=dropout, expansion=expansion)\n",
    "            self.convts_res.append(module)\n",
    "            self.links.append(ResID07N(f2,n=n,activation=activation, dropout=dropout, expansion=expansion))\n",
    "            \n",
    "        self.c = c #Total de filtros\n",
    "        self.j = j #Indice de la mayor cantidad de filtros\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" x:(b,c,h,w) \"\"\"\n",
    "\n",
    "        y = [x] #Lista de salidas. El primer valor de salida es la entrada\n",
    "        for conv,res  in zip(self.convs, self.convs_res): #Por cada convolucion de la primera seccion\n",
    "            x = conv(x) #Aplica la convolucion\n",
    "            \n",
    "            x = res(x) #Aplica residual\n",
    "            y.append(x) #Guarda la salida\n",
    "            \n",
    "        i=1\n",
    "        j=self.j\n",
    "        for convt,res,link in zip(self.convts, self.convts_res, self.links): #Por cada convolucion transpuesta y enlace\n",
    "            x = convt(x) #Aplica la convolucion transpuesta \n",
    "            \n",
    "            x = res(x) #Aplica residual\n",
    "            if(j-i>=0): x=x+link(y[j-i]) #Aplica el enlace a la primera seccion\n",
    "            i+=1\n",
    "            y.append(x) #Guarda la salida\n",
    "        \n",
    "        return y #Retorna una lista con todas las salidas\n",
    "    \n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.unet = UNetSam(filters=(1,16,32,64,128,256,128,64,32,16), n=1, activation='relu', dropout=0.0, expansion=1)\n",
    "        self.convT_o1 = nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convT_o2 = nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x -=  F.avg_pool2d(x, 101, stride=1, padding=50)\n",
    "        y = self.unet(x)\n",
    "        y1 = self.convT_o1(y[-1])\n",
    "        output_pretil = self.convT_o2(y[-1])\n",
    "        output_class = F.softmax(y1, dim=1)        \n",
    "        return output_class, output_pretil\n",
    "\n",
    "model = Unet()\n",
    "model.cuda()\n",
    "\n",
    "x = torch.randn(1, 1, 512, 512).cuda()\n",
    "y = model(x)\n",
    "y[0].shape, y[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def imagenp_pad_img_multiplo(img,multiplo=64):\n",
    "    \"\"\" Agrega filas y columnas con zeros a una imagen hasta que sus dimensiones sean multiplos del parámetro multiplo\n",
    "    img: Numpy Array float32 con la forma (h,w,c).\n",
    "    retorna: Numpy array float32 con la forma (h+deltah,w+deltaw,c).\n",
    "    \"\"\"\n",
    "    h,w,c=img.shape\n",
    "    th = int(max(np.ceil(h/multiplo)*multiplo,1.0))\n",
    "    tw = int(max(np.ceil(w/multiplo),1.0)*multiplo)\n",
    "    deltah=th-h\n",
    "    deltaw=tw-w\n",
    "    if(deltaw>0):\n",
    "        cols=np.zeros((h,deltaw,c),dtype=img.dtype)\n",
    "        img=np.concatenate([img,cols],axis=1)\n",
    "    if(deltah>0):\n",
    "        rows=np.zeros((deltah,tw,c),dtype=img.dtype)\n",
    "        img=np.concatenate([img,rows],axis=0)\n",
    "    return img\n",
    "\n",
    "def testing(real_img, mask, epoch_idx, device, path):\n",
    "    os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
    "    \n",
    "    img_shape = real_img.shape \n",
    "    \n",
    "    real_img = np.expand_dims(real_img, -1)\n",
    "    real_img = imagenp_pad_img_multiplo(real_img, 32)\n",
    "    real_img = np.expand_dims(real_img, 0)\n",
    "    real_img = torch.tensor(real_img, dtype=torch.float32, device=device)\n",
    "    real_img = real_img.permute(0,3,1,2)\n",
    "\n",
    "    print(torch.min(real_img), torch.max(real_img))\n",
    "\n",
    "    class_, pretil = model(real_img)\n",
    "\n",
    "    pretil_img = pretil[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    class_img = class_[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    pretil_img = pretil_img[:img_shape[0], :img_shape[1], :]\n",
    "    class_img = class_img[:img_shape[0], :img_shape[1], :]\n",
    "\n",
    "    mask = np.expand_dims(mask, -1)\n",
    "    class_img *= mask \n",
    "    pretil_img *= mask\n",
    "\n",
    "    pretil_img = pretil_img.astype(np.float32) \n",
    "    print(pretil_img)                                              \n",
    "    cv2.imwrite(f'{path}/pretil_epoch_{epoch_idx}.exr', pretil_img)\n",
    "\n",
    "    pretil_img = (np.clip(pretil_img,0,1) * 255).astype(np.uint8)\n",
    "    class_img = (np.clip(class_img,0,1) * 255).astype(np.uint8)    \n",
    "    class_img = class_img[...,::-1]\n",
    "\n",
    "    cv2.imwrite(f'{path}/pretil_epoch_{epoch_idx}.png',pretil_img)\n",
    "    cv2.imwrite(f'{path}/class_epoch_{epoch_idx}.png',class_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy \n",
    "# from torch.export import Dim\n",
    "\n",
    "# def pt_module_export_onnx(module, input_shapes=[(1,3,32,32),(1,3,32,32)], filename=\"module.onnx\", input_names=('input0','input1'), output_names=('output0','output1'), eval=True, float16=False, dynamic_axes_names={0:'b'}):\n",
    "#     \"\"\" export model to onnx \n",
    "#     Args:\n",
    "#         module: module to export\n",
    "#         input_shapes: shapes of the inputs\n",
    "#         filename: filename to save the onnx model.\n",
    "#         input_names: Names of the inputs for the onnx module\n",
    "#         output_names: Names of the outputs for the onnx module\n",
    "#         dynamic_axes_names={0:'b'} para batch dinamico\n",
    "#         dynamic_axes_names={0:'b',1:'h',2:'w'} para batch,height and width dinamicos\n",
    "#     \"\"\"\n",
    "#     dtype = torch.float16 if float16 else torch.float32\n",
    "#     inputs = [torch.randn(input_shape, device='cuda', dtype=dtype) for input_shape in input_shapes] #dummy inputs\n",
    "#     inputs = tuple(inputs)\n",
    "    \n",
    "#     module = copy.deepcopy(module)\n",
    "    \n",
    "#     module.cuda()\n",
    "#     if eval: module.eval()\n",
    "#     if float16: module.half()\n",
    "#     else: module.float()\n",
    "    \n",
    "#     axes_names = dynamic_axes_names\n",
    "#     dynamic_axes = {}\n",
    "#     for name in input_names:  dynamic_axes[name] = axes_names\n",
    "#     for name in output_names: dynamic_axes[name] = axes_names\n",
    "#     print(dynamic_axes)\n",
    "#     torch.onnx.export(module, \n",
    "#                       inputs, \n",
    "#                       f=filename, \n",
    "#                       input_names=input_names, \n",
    "#                       output_names=output_names, \n",
    "#                       dynamic_axes=dynamic_axes, \n",
    "#                       report=True,\n",
    "#                       optimize=True,\n",
    "#                       verify=True,\n",
    "#                       profile=True,\n",
    "#                       dump_exported_program=True,\n",
    "#                       fallback=True,\n",
    "#                       verbose=True, \n",
    "#                       dynamo=True,\n",
    "#                       external_data=False)\n",
    "    \n",
    "#     del module\n",
    "\n",
    "# model = Unet()\n",
    "# pt_module_export_onnx(model, input_shapes=[(1,1,32,32)], input_names=('x',), output_names=('class_output', 'pretil_output'),  dynamic_axes_names={0:'b',1:'h',2:'w'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Unet().cuda().eval()\n",
    "# dummy_input = torch.randn(1, 1, 1984, 1472, device='cuda') \n",
    "\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     dummy_input,\n",
    "#     'unet_dynamic.onnx',\n",
    "#     input_names=['input'],\n",
    "#     output_names=['output_class', 'output_pretil'],\n",
    "#     #dynamic_axes=dynamic_axes,\n",
    "#     opset_version=12,\n",
    "#     verbose=True,\n",
    "#     export_params=True,  # Store the trained parameter weights inside the model file\n",
    "#     do_constant_folding=True,  # Whether to execute constant folding for optimization\n",
    "#     dynamo=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# # Cargar el modelo ONNX\n",
    "# onnx_model_path = 'module.onnx'\n",
    "# ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# # Crear una entrada de prueba (igual que la que usaste para exportar el modelo)\n",
    "# dummy_input = torch.randn(1, 1, 256, 256, device='cuda').cpu().numpy()\n",
    "\n",
    "# # Ejecutar el modelo ONNX\n",
    "# outputs = ort_session.run(None, {'x': dummy_input})\n",
    "\n",
    "# # Imprimir las salidas\n",
    "# print(\"Output class:\", outputs[0].shape)\n",
    "# print(\"Output pretil:\", outputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1954, 1464)\n",
      "tensor(-14.2266, device='cuda:0') tensor(13.3157, device='cuda:0')\n",
      "[[[ 0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 5.446713 ]\n",
      "  [-1.340947 ]\n",
      "  [ 5.721717 ]]\n",
      "\n",
      " [[-0.       ]\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  ...\n",
      "  [ 2.6523829]\n",
      "  [ 5.258266 ]\n",
      "  [ 2.5021825]]\n",
      "\n",
      " [[ 0.       ]\n",
      "  [ 0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 3.9652572]\n",
      "  [ 0.9163634]\n",
      "  [ 5.240374 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]]\n",
      "\n",
      " [[ 0.       ]\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  ...\n",
      "  [-0.       ]\n",
      "  [-0.       ]\n",
      "  [-0.       ]]\n",
      "\n",
      " [[-0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dem_file = 'dem3.npz'\n",
    "real_image = np.load(dem_file)['dem']\n",
    "print(real_image.shape)\n",
    "mask = np.load(dem_file)['mask']\n",
    "model = Unet()\n",
    "\n",
    "for i in range(100):\n",
    "    model.load_state_dict(torch.load(f'weigths/model_epoch_{i+1}.pth'))\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    testing(real_image, mask, i, 'cuda', 'testing/inference_dem_3')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
