{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512, 512]), torch.Size([1, 1, 512, 512]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from zipfile import ZipFile\n",
    "\n",
    "INPLACE=False \n",
    "CONVPAD='zeros'\n",
    "\n",
    "def pt_get_activation(activation) -> nn.Module:\n",
    "    \"\"\" Retorna un modulo de activacion por nombre.\n",
    "    Retorna None si el nombre no coincide \"\"\"\n",
    "    if(activation is None): return None\n",
    "    elif isinstance(activation,nn.Module): return activation\n",
    "    elif(activation=='relu'): return nn.ReLU(inplace=INPLACE)\n",
    "    elif(activation=='elu'): return nn.ELU(inplace=INPLACE)\n",
    "    elif(activation=='leakyrelu'): return nn.LeakyReLU(inplace=INPLACE)\n",
    "    elif(activation=='sigmoid'): return nn.Sigmoid()\n",
    "    elif(activation=='logsigmoid'): return nn.LogSigmoid()\n",
    "    elif(activation=='softmax'): return nn.Softmax(dim=1)\n",
    "    elif(activation=='softmin'): return nn.Softmin(dim=1)\n",
    "    elif(activation=='logsoftmax'): return nn.LogSoftmax(dim=1)\n",
    "    elif(activation=='prelu'): return nn.PReLU()\n",
    "    elif(activation=='relu6'): return nn.ReLU6(inplace=INPLACE)\n",
    "    elif(activation=='rrelu'): return nn.RReLU(inplace=INPLACE)\n",
    "    elif(activation=='selu'): return nn.SELU(inplace=INPLACE)\n",
    "    elif(activation=='celu'): return nn.CELU(inplace=INPLACE)\n",
    "    elif(activation=='gelu'): return nn.GELU(approximate='tanh')\n",
    "    elif(activation=='silu'): return nn.SiLU(inplace=INPLACE)\n",
    "    elif(activation=='mish'): return nn.Mish(inplace=INPLACE)\n",
    "    elif(activation=='softplus'): return nn.Softplus()\n",
    "    elif(activation=='softsign'): return nn.Softsign()\n",
    "    elif(activation=='softshrink'): return nn.Softshrink()\n",
    "    elif(activation=='tanh'): return nn.Tanh()\n",
    "    return None\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\" Convolution + Activation \"\"\"\n",
    "        \n",
    "    def __init__(self, ic:int, oc:int, k=3, s=1, p=1, bias=True, activation=None, scale=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ic, oc, kernel_size=k, stride=s, padding=p, bias=bias, padding_mode=CONVPAD)\n",
    "        self.activation = pt_get_activation(activation)\n",
    "        self.scale = scale\n",
    "        self.residual = residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        x = self.conv(x)\n",
    "        if(self.activation is not None): x = self.activation(x)\n",
    "        if(self.scale is not None): x = self.scale(x)\n",
    "        if(self.residual): x = x0 + x\n",
    "        return x\n",
    "    \n",
    "class ResID07(nn.Module):\n",
    "    \"\"\" Bloque residual bn+act+conv+bn+act+conv con ajuste de dimensiones espaciales y semanticas \"\"\" \n",
    "    def __init__(self, ic:int, oc:int, activation='relu', dropout=0.0, expansion=1, resample=None):\n",
    "        super().__init__()\n",
    "        mc = int(ic*expansion)\n",
    "        self.norm1 = torch.nn.BatchNorm2d(ic, momentum=0.01)\n",
    "        self.act1  = pt_get_activation(activation) \n",
    "        self.conv1 = Conv(ic,mc,k=3,s=1,p=1)\n",
    "        \n",
    "        self.resample = resample\n",
    "        \n",
    "        self.norm2 = torch.nn.BatchNorm2d(mc, momentum=0.01)\n",
    "        self.act2  = pt_get_activation(activation)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout>0.0 else None\n",
    "        self.conv2 = Conv(mc,oc,k=3,s=1,p=1)\n",
    "        \n",
    "        self.conv3 = Conv(ic,oc,k=1,s=1,p=0) if ic!=oc else None\n",
    "        \n",
    "    def forward(self, x, emb=None):\n",
    "        x0 = x\n",
    "        if(self.norm1 is not None): x = self.norm1(x)\n",
    "        if(self.act1  is not None): x = self.act1(x)\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        if(emb is not None): x = x+emb\n",
    "        \n",
    "        if(self.resample is not None):\n",
    "            x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
    "            x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
    "        \n",
    "        if(self.norm2   is not None): x = self.norm2(x)\n",
    "        if(self.act2    is not None): x = self.act2(x)\n",
    "        if(self.dropout is not None): x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        if self.conv3 is not None: x0 = self.conv3(x0) #(b,oc,h,w) Ajusta los canales para que sean iguales.\n",
    "        \n",
    "        return x0 + x\n",
    "    \n",
    "class ResID07N(nn.Module):\n",
    "    \"\"\" N bloques ResID07 \"\"\"\n",
    "    def __init__(self, ic:int, n=2, activation='relu', dropout=0.0, expansion=2):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for _ in range(n): self.layers.append(ResID07(ic,ic, activation=activation, dropout=dropout, expansion=expansion))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class UNetSam(nn.Module):\n",
    "    \"\"\" UNET\n",
    "    La primera seccion aplica ResID07 con resample=0.5 varias veces para reducir  la resolucion y aumentar la cantidad de filtros, hasta llegar a la maxima cantidad de filtros.\n",
    "    La segunda seccion aplica ResID07 con resample=2.0 varias veces para aumentar la resolucion y reducir  la cantidad de filtros.\n",
    "    Agrega enlaces entre la primera y segunda seccion.\n",
    "    Retorna una lista 'y' con todas las salidas de cada nivel, siendo y[0] la entrada e y[-1] la ultima salida\n",
    "    activation2: Activacion de SAM: sigmoid, softmax8, softmax16, softmax32\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filters=(1,16,32,64,128,256,128,64,32,16), n=1, activation='relu', dropout=0.0, expansion=1):\n",
    "        super().__init__()\n",
    "        c = len(filters) #Total de filtros\n",
    "        j = np.argmax(filters) #Indice de la mayor cantidad de filtros (Parte mas ancha de la UNet)\n",
    "        \n",
    "        self.convs = nn.ModuleList() #Lista de modulos ConvBnAct\n",
    "        self.convs_res = nn.ModuleList() #Lista de modulos ResID01N\n",
    "\n",
    "        for i in range(1,j+1):\n",
    "            f1 = filters[i-1]\n",
    "            f2 = filters[i]\n",
    "            self.convs.append( ResID07(f1,f2,resample=0.5,activation=activation, dropout=dropout, expansion=expansion))\n",
    "            module = ResID07N(f2,n=n,activation=activation, dropout=dropout, expansion=expansion)\n",
    "            self.convs_res.append(module)\n",
    "            \n",
    "        self.convts = nn.ModuleList() #Lista de modulos ConvTBnAct (Convolucion Transpuesta)\n",
    "        self.convts_res = nn.ModuleList() #Lista de modulos ResID01N\n",
    "        self.links = nn.ModuleList() #Lista de modulos ConvBnAct para enlazar la primera seccion con la segunda\n",
    "        for i in range(j+1,c):\n",
    "            f1 = filters[i-1]\n",
    "            f2 = filters[i]\n",
    "            self.convts.append(ResID07(f1,f2,resample=2,activation=activation, dropout=dropout, expansion=expansion))\n",
    "            module = ResID07N(f2,n=n,activation=activation, dropout=dropout, expansion=expansion)\n",
    "            self.convts_res.append(module)\n",
    "            self.links.append(ResID07N(f2,n=n,activation=activation, dropout=dropout, expansion=expansion))\n",
    "            \n",
    "        self.c = c #Total de filtros\n",
    "        self.j = j #Indice de la mayor cantidad de filtros\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" x:(b,c,h,w) \"\"\"\n",
    "\n",
    "        y = [x] #Lista de salidas. El primer valor de salida es la entrada\n",
    "        for conv,res  in zip(self.convs, self.convs_res): #Por cada convolucion de la primera seccion\n",
    "            x = conv(x) #Aplica la convolucion\n",
    "            \n",
    "            x = res(x) #Aplica residual\n",
    "            y.append(x) #Guarda la salida\n",
    "            \n",
    "        i=1\n",
    "        j=self.j\n",
    "        for convt,res,link in zip(self.convts, self.convts_res, self.links): #Por cada convolucion transpuesta y enlace\n",
    "            x = convt(x) #Aplica la convolucion transpuesta \n",
    "            \n",
    "            x = res(x) #Aplica residual\n",
    "            if(j-i>=0): x=x+link(y[j-i]) #Aplica el enlace a la primera seccion\n",
    "            i+=1\n",
    "            y.append(x) #Guarda la salida\n",
    "        \n",
    "        return y #Retorna una lista con todas las salidas\n",
    "    \n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.unet = UNetSam(filters=(1,16,32,64,128,256,128,64,32,16), n=1, activation='relu', dropout=0.0, expansion=1)\n",
    "        self.convT_o1 = nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.convT_o2 = nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x -=  F.avg_pool2d(x, 101, stride=1, padding=50)\n",
    "        y = self.unet(x)\n",
    "        y1 = self.convT_o1(y[-1])\n",
    "        output_pretil = self.convT_o2(y[-1])\n",
    "        output_class = F.softmax(y1, dim=1)        \n",
    "        return output_class, output_pretil\n",
    "\n",
    "model = Unet()\n",
    "model.cuda()\n",
    "\n",
    "x = torch.randn(1, 1, 512, 512).cuda()\n",
    "y = model(x)\n",
    "y[0].shape, y[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def imagenp_pad_img_multiplo(img,multiplo=64):\n",
    "    \"\"\" Agrega filas y columnas con zeros a una imagen hasta que sus dimensiones sean multiplos del parámetro multiplo\n",
    "    img: Numpy Array float32 con la forma (h,w,c).\n",
    "    retorna: Numpy array float32 con la forma (h+deltah,w+deltaw,c).\n",
    "    \"\"\"\n",
    "    h,w,c=img.shape\n",
    "    th = int(max(np.ceil(h/multiplo)*multiplo,1.0))\n",
    "    tw = int(max(np.ceil(w/multiplo),1.0)*multiplo)\n",
    "    deltah=th-h\n",
    "    deltaw=tw-w\n",
    "    if(deltaw>0):\n",
    "        cols=np.zeros((h,deltaw,c),dtype=img.dtype)\n",
    "        img=np.concatenate([img,cols],axis=1)\n",
    "    if(deltah>0):\n",
    "        rows=np.zeros((deltah,tw,c),dtype=img.dtype)\n",
    "        img=np.concatenate([img,rows],axis=0)\n",
    "    return img\n",
    "\n",
    "def testing(real_img, mask, epoch_idx, device, path):\n",
    "    os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
    "    \n",
    "    img_shape = real_img.shape \n",
    "    \n",
    "    real_img = np.expand_dims(real_img, -1)\n",
    "    real_img = imagenp_pad_img_multiplo(real_img, 32)\n",
    "    real_img = np.expand_dims(real_img, 0)\n",
    "    real_img = torch.tensor(real_img, dtype=torch.float32, device=device)\n",
    "    real_img = real_img.permute(0,3,1,2)\n",
    "\n",
    "    class_, pretil = model(real_img)\n",
    "\n",
    "    pretil_img = pretil[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    class_img = class_[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    pretil_img = pretil_img[:img_shape[0], :img_shape[1], :]\n",
    "    class_img = class_img[:img_shape[0], :img_shape[1], :]\n",
    "\n",
    "    mask = np.expand_dims(mask, -1)\n",
    "    class_img *= mask \n",
    "    pretil_img *= mask\n",
    "\n",
    "    pretil_img = pretil_img.astype(np.float32) \n",
    "    print(pretil_img)                                              \n",
    "    cv2.imwrite(f'{path}/pretil_epoch_{epoch_idx}.exr', pretil_img)\n",
    "\n",
    "    pretil_img = (np.clip(pretil_img,0,1) * 255).astype(np.uint8)\n",
    "    class_img = (np.clip(class_img,0,1) * 255).astype(np.uint8)    \n",
    "    class_img = class_img[...,::-1]\n",
    "\n",
    "    cv2.imwrite(f'{path}/pretil_epoch_{epoch_idx}.png',pretil_img)\n",
    "    cv2.imwrite(f'{path}/class_epoch_{epoch_idx}.png',class_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy \n",
    "\n",
    "# def pt_module_export_onnx(module, input_shapes=[(1,3,32,32),(1,3,32,32)], filename=\"module.onnx\", input_names=('input0','input1'), output_names=('output0','output1'), eval=True, float16=False, dynamic_axes_names={0:'b'}):\n",
    "#     \"\"\" export model to onnx \n",
    "#     Args:\n",
    "#         module: module to export\n",
    "#         input_shapes: shapes of the inputs\n",
    "#         filename: filename to save the onnx model.\n",
    "#         input_names: Names of the inputs for the onnx module\n",
    "#         output_names: Names of the outputs for the onnx module\n",
    "#         dynamic_axes_names={0:'b'} para batch dinamico\n",
    "#         dynamic_axes_names={0:'b',1:'h',2:'w'} para batch,height and width dinamicos\n",
    "#     \"\"\"\n",
    "#     dtype = torch.float16 if float16 else torch.float32\n",
    "#     inputs = [torch.randn(input_shape, device='cuda', dtype=dtype) for input_shape in input_shapes] #dummy inputs\n",
    "#     inputs = tuple(inputs)\n",
    "    \n",
    "#     module = copy.deepcopy(module)\n",
    "    \n",
    "#     module.cuda()\n",
    "#     if eval: module.eval()\n",
    "#     if float16: module.half()\n",
    "#     else: module.float()\n",
    "    \n",
    "#     axes_names = dynamic_axes_names\n",
    "#     dynamic_axes = {}\n",
    "#     for name in input_names:  dynamic_axes[name] = axes_names\n",
    "#     for name in output_names: dynamic_axes[name] = axes_names\n",
    "#     print(dynamic_axes)\n",
    "#     torch.onnx.export(module, inputs, f=filename, verbose=True, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes )\n",
    "    \n",
    "#     del module\n",
    "\n",
    "# model = Unet()\n",
    "# pt_module_export_onnx(model, input_shapes=[(1,1,32,32)], input_names=('x',), output_names=('class_output', 'pretil_output'),  dynamic_axes_names={0:'b',1:'h',2:'w'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `Unet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `Unet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'pkg.onnxscript.torch_lib.common': 1, '': 18, 'pkg.onnxscript.torch_lib': 1},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.6.0+cu124',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,1,1984,1472]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output_class\"<FLOAT,[1,3,1984,1472]>,\n",
       "                %\"output_pretil\"<FLOAT,[1,1,1984,1472]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"unet.convs.0.norm1.weight\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm1.bias\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.conv1.conv.weight\"<FLOAT,[1,1,3,3]>,\n",
       "                %\"unet.convs.0.conv1.conv.bias\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm2.weight\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm2.bias\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.conv2.conv.weight\"<FLOAT,[16,1,3,3]>,\n",
       "                %\"unet.convs.0.conv2.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.0.conv3.conv.weight\"<FLOAT,[16,1,1,1]>,\n",
       "                %\"unet.convs.0.conv3.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm1.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm1.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.conv1.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.convs.1.conv1.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm2.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm2.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.conv2.conv.weight\"<FLOAT,[32,16,3,3]>,\n",
       "                %\"unet.convs.1.conv2.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.1.conv3.conv.weight\"<FLOAT,[32,16,1,1]>,\n",
       "                %\"unet.convs.1.conv3.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm1.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm1.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.conv1.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.convs.2.conv1.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm2.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm2.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.conv2.conv.weight\"<FLOAT,[64,32,3,3]>,\n",
       "                %\"unet.convs.2.conv2.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.2.conv3.conv.weight\"<FLOAT,[64,32,1,1]>,\n",
       "                %\"unet.convs.2.conv3.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm1.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm1.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.conv1.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.convs.3.conv1.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm2.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm2.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.conv2.conv.weight\"<FLOAT,[128,64,3,3]>,\n",
       "                %\"unet.convs.3.conv2.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.3.conv3.conv.weight\"<FLOAT,[128,64,1,1]>,\n",
       "                %\"unet.convs.3.conv3.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm1.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm1.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.conv1.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.convs.4.conv1.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm2.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm2.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.conv2.conv.weight\"<FLOAT,[256,128,3,3]>,\n",
       "                %\"unet.convs.4.conv2.conv.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convs.4.conv3.conv.weight\"<FLOAT,[256,128,1,1]>,\n",
       "                %\"unet.convs.4.conv3.conv.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm1.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm1.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.conv1.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.convs_res.0.layers.0.conv1.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm2.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm2.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.conv2.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.convs_res.0.layers.0.conv2.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm1.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm1.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.conv1.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.convs_res.1.layers.0.conv1.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm2.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm2.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.conv2.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.convs_res.1.layers.0.conv2.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm1.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm1.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.conv1.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.convs_res.2.layers.0.conv1.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm2.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm2.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.conv2.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.convs_res.2.layers.0.conv2.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm1.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm1.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.conv1.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.convs_res.3.layers.0.conv1.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm2.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm2.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.conv2.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.convs_res.3.layers.0.conv2.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm1.weight\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm1.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.conv1.conv.weight\"<FLOAT,[256,256,3,3]>,\n",
       "                %\"unet.convs_res.4.layers.0.conv1.conv.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm2.weight\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm2.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.conv2.conv.weight\"<FLOAT,[256,256,3,3]>,\n",
       "                %\"unet.convs_res.4.layers.0.conv2.conv.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm1.weight\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm1.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.conv1.conv.weight\"<FLOAT,[256,256,3,3]>,\n",
       "                %\"unet.convts.0.conv1.conv.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm2.weight\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm2.bias\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.conv2.conv.weight\"<FLOAT,[128,256,3,3]>,\n",
       "                %\"unet.convts.0.conv2.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.0.conv3.conv.weight\"<FLOAT,[128,256,1,1]>,\n",
       "                %\"unet.convts.0.conv3.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm1.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm1.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.conv1.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.convts.1.conv1.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm2.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm2.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.conv2.conv.weight\"<FLOAT,[64,128,3,3]>,\n",
       "                %\"unet.convts.1.conv2.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.1.conv3.conv.weight\"<FLOAT,[64,128,1,1]>,\n",
       "                %\"unet.convts.1.conv3.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm1.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm1.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.conv1.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.convts.2.conv1.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm2.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm2.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.conv2.conv.weight\"<FLOAT,[32,64,3,3]>,\n",
       "                %\"unet.convts.2.conv2.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.2.conv3.conv.weight\"<FLOAT,[32,64,1,1]>,\n",
       "                %\"unet.convts.2.conv3.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm1.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm1.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.conv1.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.convts.3.conv1.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm2.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm2.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.conv2.conv.weight\"<FLOAT,[16,32,3,3]>,\n",
       "                %\"unet.convts.3.conv2.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convts.3.conv3.conv.weight\"<FLOAT,[16,32,1,1]>,\n",
       "                %\"unet.convts.3.conv3.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm1.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm1.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.conv1.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.convts_res.0.layers.0.conv1.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm2.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm2.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.conv2.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.convts_res.0.layers.0.conv2.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm1.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm1.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.conv1.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.convts_res.1.layers.0.conv1.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm2.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm2.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.conv2.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.convts_res.1.layers.0.conv2.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm1.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm1.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.conv1.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.convts_res.2.layers.0.conv1.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm2.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm2.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.conv2.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.convts_res.2.layers.0.conv2.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm1.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm1.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.conv1.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.convts_res.3.layers.0.conv1.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm2.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm2.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.conv2.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.convts_res.3.layers.0.conv2.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.links.0.layers.0.norm1.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm1.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.conv1.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.links.0.layers.0.conv1.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm2.weight\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm2.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.conv2.conv.weight\"<FLOAT,[128,128,3,3]>,\n",
       "                %\"unet.links.0.layers.0.conv2.conv.bias\"<FLOAT,[128]>,\n",
       "                %\"unet.links.1.layers.0.norm1.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm1.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.conv1.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.links.1.layers.0.conv1.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm2.weight\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm2.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.conv2.conv.weight\"<FLOAT,[64,64,3,3]>,\n",
       "                %\"unet.links.1.layers.0.conv2.conv.bias\"<FLOAT,[64]>,\n",
       "                %\"unet.links.2.layers.0.norm1.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm1.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.conv1.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.links.2.layers.0.conv1.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm2.weight\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm2.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.conv2.conv.weight\"<FLOAT,[32,32,3,3]>,\n",
       "                %\"unet.links.2.layers.0.conv2.conv.bias\"<FLOAT,[32]>,\n",
       "                %\"unet.links.3.layers.0.norm1.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm1.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.conv1.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.links.3.layers.0.conv1.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm2.weight\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm2.bias\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.conv2.conv.weight\"<FLOAT,[16,16,3,3]>,\n",
       "                %\"unet.links.3.layers.0.conv2.conv.bias\"<FLOAT,[16]>,\n",
       "                %\"convT_o1.weight\"<FLOAT,[16,3,3,3]>,\n",
       "                %\"convT_o1.bias\"<FLOAT,[3]>,\n",
       "                %\"convT_o2.weight\"<FLOAT,[16,1,3,3]>,\n",
       "                %\"convT_o2.bias\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm1.running_mean\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm1.running_var\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.0.norm2.running_mean\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm2.running_var\"<FLOAT,[1]>,\n",
       "                %\"unet.convs.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.1.norm1.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm1.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.1.norm2.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm2.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.convs.1.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.2.norm1.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm1.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.2.norm2.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm2.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convs.2.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.3.norm1.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm1.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.3.norm2.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm2.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convs.3.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.4.norm1.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm1.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs.4.norm2.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm2.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convs.4.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm1.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm1.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm2.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm2.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.convs_res.0.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm1.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm1.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm2.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm2.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convs_res.1.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm1.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm1.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm2.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm2.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convs_res.2.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm1.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm1.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm2.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm2.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convs_res.3.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm1.running_mean\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm1.running_var\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm2.running_mean\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm2.running_var\"<FLOAT,[256]>,\n",
       "                %\"unet.convs_res.4.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.0.norm1.running_mean\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm1.running_var\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.0.norm2.running_mean\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm2.running_var\"<FLOAT,[256]>,\n",
       "                %\"unet.convts.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.1.norm1.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm1.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.1.norm2.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm2.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convts.1.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.2.norm1.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm1.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.2.norm2.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm2.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convts.2.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.3.norm1.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm1.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts.3.norm2.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm2.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convts.3.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm1.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm1.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm2.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm2.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.convts_res.0.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm1.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm1.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm2.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm2.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.convts_res.1.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm1.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm1.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm2.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm2.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.convts_res.2.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm1.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm1.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm2.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm2.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.convts_res.3.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.0.layers.0.norm1.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm1.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.0.layers.0.norm2.running_mean\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm2.running_var\"<FLOAT,[128]>,\n",
       "                %\"unet.links.0.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.1.layers.0.norm1.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm1.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.1.layers.0.norm2.running_mean\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm2.running_var\"<FLOAT,[64]>,\n",
       "                %\"unet.links.1.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.2.layers.0.norm1.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm1.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.2.layers.0.norm2.running_mean\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm2.running_var\"<FLOAT,[32]>,\n",
       "                %\"unet.links.2.layers.0.norm2.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.3.layers.0.norm1.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm1.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm1.num_batches_tracked\"<INT64,[]>,\n",
       "                %\"unet.links.3.layers.0.norm2.running_mean\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm2.running_var\"<FLOAT,[16]>,\n",
       "                %\"unet.links.3.layers.0.norm2.num_batches_tracked\"<INT64,[]>\n",
       "            ),\n",
       "        ) {\n",
       "              0 |  # node_AveragePool_0\n",
       "                   %\"avg_pool2d\"<FLOAT,[1,1,1984,1472]> ⬅️ ::AveragePool(%\"input\") {auto_pad=NOTSET, ceil_mode=False, count_include_pad=True, kernel_shape=[101, 101], pads=[50, 50, 50, 50], strides=[1, 1]}\n",
       "              1 |  # node_Sub_1\n",
       "                   %\"sub\"<FLOAT,[1,1,1984,1472]> ⬅️ ::Sub(%\"input\", %\"avg_pool2d\")\n",
       "              2 |  # node_Constant_2\n",
       "                   %\"val_0\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "              3 |  # node__aten_native_batch_norm_inference_onnx_3\n",
       "                   %\"getitem\"<FLOAT,[1,1,1984,1472]>, %\"_native_batch_norm_legit_no_training__1\"<FLOAT,[1]>, %\"_native_batch_norm_legit_no_training__2\"<FLOAT,[1]>, %\"val_1\"<?,?>, %\"val_2\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"sub\", %\"unet.convs.0.norm1.weight\", %\"unet.convs.0.norm1.bias\", %\"unet.convs.0.norm1.running_mean\", %\"unet.convs.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "              4 |  # node_Relu_4\n",
       "                   %\"relu\"<FLOAT,[1,1,1984,1472]> ⬅️ ::Relu(%\"getitem\")\n",
       "              5 |  # node_Conv_5\n",
       "                   %\"conv2d\"<FLOAT,[1,1,1984,1472]> ⬅️ ::Conv(%\"relu\", %\"unet.convs.0.conv1.conv.weight\", %\"unet.convs.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "              6 |  # node_Constant_6\n",
       "                   %\"val_3\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "              7 |  # node_Resize_7\n",
       "                   %\"upsample_bilinear2d\"<FLOAT,[1,1,992,736]> ⬅️ ::Resize(%\"conv2d\", None, %\"val_3\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "              8 |  # node_Constant_8\n",
       "                   %\"val_4\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "              9 |  # node_Resize_9\n",
       "                   %\"upsample_bilinear2d_1\"<FLOAT,[1,1,992,736]> ⬅️ ::Resize(%\"sub\", None, %\"val_4\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             10 |  # node_Constant_10\n",
       "                   %\"val_5\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             11 |  # node__aten_native_batch_norm_inference_onnx_11\n",
       "                   %\"getitem_3\"<FLOAT,[1,1,992,736]>, %\"_native_batch_norm_legit_no_training_1__1\"<FLOAT,[1]>, %\"_native_batch_norm_legit_no_training_1__2\"<FLOAT,[1]>, %\"val_6\"<?,?>, %\"val_7\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d\", %\"unet.convs.0.norm2.weight\", %\"unet.convs.0.norm2.bias\", %\"unet.convs.0.norm2.running_mean\", %\"unet.convs.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             12 |  # node_Relu_12\n",
       "                   %\"relu_1\"<FLOAT,[1,1,992,736]> ⬅️ ::Relu(%\"getitem_3\")\n",
       "             13 |  # node_Conv_13\n",
       "                   %\"conv2d_1\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_1\", %\"unet.convs.0.conv2.conv.weight\", %\"unet.convs.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             14 |  # node_Conv_14\n",
       "                   %\"conv2d_2\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"upsample_bilinear2d_1\", %\"unet.convs.0.conv3.conv.weight\", %\"unet.convs.0.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "             15 |  # node_Add_15\n",
       "                   %\"add\"<FLOAT,[1,16,992,736]> ⬅️ ::Add(%\"conv2d_2\", %\"conv2d_1\")\n",
       "             16 |  # node_Constant_16\n",
       "                   %\"val_8\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             17 |  # node__aten_native_batch_norm_inference_onnx_17\n",
       "                   %\"getitem_6\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_2__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_2__2\"<FLOAT,[16]>, %\"val_9\"<?,?>, %\"val_10\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add\", %\"unet.convs_res.0.layers.0.norm1.weight\", %\"unet.convs_res.0.layers.0.norm1.bias\", %\"unet.convs_res.0.layers.0.norm1.running_mean\", %\"unet.convs_res.0.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             18 |  # node_Relu_18\n",
       "                   %\"relu_2\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_6\")\n",
       "             19 |  # node_Conv_19\n",
       "                   %\"conv2d_3\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_2\", %\"unet.convs_res.0.layers.0.conv1.conv.weight\", %\"unet.convs_res.0.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             20 |  # node_Constant_20\n",
       "                   %\"val_11\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             21 |  # node__aten_native_batch_norm_inference_onnx_21\n",
       "                   %\"getitem_9\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_3__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_3__2\"<FLOAT,[16]>, %\"val_12\"<?,?>, %\"val_13\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_3\", %\"unet.convs_res.0.layers.0.norm2.weight\", %\"unet.convs_res.0.layers.0.norm2.bias\", %\"unet.convs_res.0.layers.0.norm2.running_mean\", %\"unet.convs_res.0.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             22 |  # node_Relu_22\n",
       "                   %\"relu_3\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_9\")\n",
       "             23 |  # node_Conv_23\n",
       "                   %\"conv2d_4\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_3\", %\"unet.convs_res.0.layers.0.conv2.conv.weight\", %\"unet.convs_res.0.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             24 |  # node_Add_24\n",
       "                   %\"add_1\"<FLOAT,[1,16,992,736]> ⬅️ ::Add(%\"add\", %\"conv2d_4\")\n",
       "             25 |  # node_Constant_25\n",
       "                   %\"val_14\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             26 |  # node__aten_native_batch_norm_inference_onnx_26\n",
       "                   %\"getitem_12\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_4__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_4__2\"<FLOAT,[16]>, %\"val_15\"<?,?>, %\"val_16\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_1\", %\"unet.convs.1.norm1.weight\", %\"unet.convs.1.norm1.bias\", %\"unet.convs.1.norm1.running_mean\", %\"unet.convs.1.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             27 |  # node_Relu_27\n",
       "                   %\"relu_4\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_12\")\n",
       "             28 |  # node_Conv_28\n",
       "                   %\"conv2d_5\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_4\", %\"unet.convs.1.conv1.conv.weight\", %\"unet.convs.1.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             29 |  # node_Constant_29\n",
       "                   %\"val_17\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             30 |  # node_Resize_30\n",
       "                   %\"upsample_bilinear2d_2\"<FLOAT,[1,16,496,368]> ⬅️ ::Resize(%\"conv2d_5\", None, %\"val_17\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             31 |  # node_Constant_31\n",
       "                   %\"val_18\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             32 |  # node_Resize_32\n",
       "                   %\"upsample_bilinear2d_3\"<FLOAT,[1,16,496,368]> ⬅️ ::Resize(%\"add_1\", None, %\"val_18\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             33 |  # node_Constant_33\n",
       "                   %\"val_19\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             34 |  # node__aten_native_batch_norm_inference_onnx_34\n",
       "                   %\"getitem_15\"<FLOAT,[1,16,496,368]>, %\"_native_batch_norm_legit_no_training_5__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_5__2\"<FLOAT,[16]>, %\"val_20\"<?,?>, %\"val_21\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_2\", %\"unet.convs.1.norm2.weight\", %\"unet.convs.1.norm2.bias\", %\"unet.convs.1.norm2.running_mean\", %\"unet.convs.1.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             35 |  # node_Relu_35\n",
       "                   %\"relu_5\"<FLOAT,[1,16,496,368]> ⬅️ ::Relu(%\"getitem_15\")\n",
       "             36 |  # node_Conv_36\n",
       "                   %\"conv2d_6\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_5\", %\"unet.convs.1.conv2.conv.weight\", %\"unet.convs.1.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             37 |  # node_Conv_37\n",
       "                   %\"conv2d_7\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"upsample_bilinear2d_3\", %\"unet.convs.1.conv3.conv.weight\", %\"unet.convs.1.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "             38 |  # node_Add_38\n",
       "                   %\"add_2\"<FLOAT,[1,32,496,368]> ⬅️ ::Add(%\"conv2d_7\", %\"conv2d_6\")\n",
       "             39 |  # node_Constant_39\n",
       "                   %\"val_22\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             40 |  # node__aten_native_batch_norm_inference_onnx_40\n",
       "                   %\"getitem_18\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_6__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_6__2\"<FLOAT,[32]>, %\"val_23\"<?,?>, %\"val_24\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_2\", %\"unet.convs_res.1.layers.0.norm1.weight\", %\"unet.convs_res.1.layers.0.norm1.bias\", %\"unet.convs_res.1.layers.0.norm1.running_mean\", %\"unet.convs_res.1.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             41 |  # node_Relu_41\n",
       "                   %\"relu_6\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_18\")\n",
       "             42 |  # node_Conv_42\n",
       "                   %\"conv2d_8\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_6\", %\"unet.convs_res.1.layers.0.conv1.conv.weight\", %\"unet.convs_res.1.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             43 |  # node_Constant_43\n",
       "                   %\"val_25\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             44 |  # node__aten_native_batch_norm_inference_onnx_44\n",
       "                   %\"getitem_21\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_7__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_7__2\"<FLOAT,[32]>, %\"val_26\"<?,?>, %\"val_27\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_8\", %\"unet.convs_res.1.layers.0.norm2.weight\", %\"unet.convs_res.1.layers.0.norm2.bias\", %\"unet.convs_res.1.layers.0.norm2.running_mean\", %\"unet.convs_res.1.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             45 |  # node_Relu_45\n",
       "                   %\"relu_7\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_21\")\n",
       "             46 |  # node_Conv_46\n",
       "                   %\"conv2d_9\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_7\", %\"unet.convs_res.1.layers.0.conv2.conv.weight\", %\"unet.convs_res.1.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             47 |  # node_Add_47\n",
       "                   %\"add_3\"<FLOAT,[1,32,496,368]> ⬅️ ::Add(%\"add_2\", %\"conv2d_9\")\n",
       "             48 |  # node_Constant_48\n",
       "                   %\"val_28\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             49 |  # node__aten_native_batch_norm_inference_onnx_49\n",
       "                   %\"getitem_24\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_8__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_8__2\"<FLOAT,[32]>, %\"val_29\"<?,?>, %\"val_30\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_3\", %\"unet.convs.2.norm1.weight\", %\"unet.convs.2.norm1.bias\", %\"unet.convs.2.norm1.running_mean\", %\"unet.convs.2.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             50 |  # node_Relu_50\n",
       "                   %\"relu_8\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_24\")\n",
       "             51 |  # node_Conv_51\n",
       "                   %\"conv2d_10\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_8\", %\"unet.convs.2.conv1.conv.weight\", %\"unet.convs.2.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             52 |  # node_Constant_52\n",
       "                   %\"val_31\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             53 |  # node_Resize_53\n",
       "                   %\"upsample_bilinear2d_4\"<FLOAT,[1,32,248,184]> ⬅️ ::Resize(%\"conv2d_10\", None, %\"val_31\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             54 |  # node_Constant_54\n",
       "                   %\"val_32\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             55 |  # node_Resize_55\n",
       "                   %\"upsample_bilinear2d_5\"<FLOAT,[1,32,248,184]> ⬅️ ::Resize(%\"add_3\", None, %\"val_32\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             56 |  # node_Constant_56\n",
       "                   %\"val_33\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             57 |  # node__aten_native_batch_norm_inference_onnx_57\n",
       "                   %\"getitem_27\"<FLOAT,[1,32,248,184]>, %\"_native_batch_norm_legit_no_training_9__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_9__2\"<FLOAT,[32]>, %\"val_34\"<?,?>, %\"val_35\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_4\", %\"unet.convs.2.norm2.weight\", %\"unet.convs.2.norm2.bias\", %\"unet.convs.2.norm2.running_mean\", %\"unet.convs.2.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             58 |  # node_Relu_58\n",
       "                   %\"relu_9\"<FLOAT,[1,32,248,184]> ⬅️ ::Relu(%\"getitem_27\")\n",
       "             59 |  # node_Conv_59\n",
       "                   %\"conv2d_11\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_9\", %\"unet.convs.2.conv2.conv.weight\", %\"unet.convs.2.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             60 |  # node_Conv_60\n",
       "                   %\"conv2d_12\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"upsample_bilinear2d_5\", %\"unet.convs.2.conv3.conv.weight\", %\"unet.convs.2.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "             61 |  # node_Add_61\n",
       "                   %\"add_4\"<FLOAT,[1,64,248,184]> ⬅️ ::Add(%\"conv2d_12\", %\"conv2d_11\")\n",
       "             62 |  # node_Constant_62\n",
       "                   %\"val_36\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             63 |  # node__aten_native_batch_norm_inference_onnx_63\n",
       "                   %\"getitem_30\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_10__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_10__2\"<FLOAT,[64]>, %\"val_37\"<?,?>, %\"val_38\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_4\", %\"unet.convs_res.2.layers.0.norm1.weight\", %\"unet.convs_res.2.layers.0.norm1.bias\", %\"unet.convs_res.2.layers.0.norm1.running_mean\", %\"unet.convs_res.2.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             64 |  # node_Relu_64\n",
       "                   %\"relu_10\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_30\")\n",
       "             65 |  # node_Conv_65\n",
       "                   %\"conv2d_13\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_10\", %\"unet.convs_res.2.layers.0.conv1.conv.weight\", %\"unet.convs_res.2.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             66 |  # node_Constant_66\n",
       "                   %\"val_39\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             67 |  # node__aten_native_batch_norm_inference_onnx_67\n",
       "                   %\"getitem_33\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_11__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_11__2\"<FLOAT,[64]>, %\"val_40\"<?,?>, %\"val_41\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_13\", %\"unet.convs_res.2.layers.0.norm2.weight\", %\"unet.convs_res.2.layers.0.norm2.bias\", %\"unet.convs_res.2.layers.0.norm2.running_mean\", %\"unet.convs_res.2.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             68 |  # node_Relu_68\n",
       "                   %\"relu_11\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_33\")\n",
       "             69 |  # node_Conv_69\n",
       "                   %\"conv2d_14\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_11\", %\"unet.convs_res.2.layers.0.conv2.conv.weight\", %\"unet.convs_res.2.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             70 |  # node_Add_70\n",
       "                   %\"add_5\"<FLOAT,[1,64,248,184]> ⬅️ ::Add(%\"add_4\", %\"conv2d_14\")\n",
       "             71 |  # node_Constant_71\n",
       "                   %\"val_42\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             72 |  # node__aten_native_batch_norm_inference_onnx_72\n",
       "                   %\"getitem_36\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_12__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_12__2\"<FLOAT,[64]>, %\"val_43\"<?,?>, %\"val_44\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_5\", %\"unet.convs.3.norm1.weight\", %\"unet.convs.3.norm1.bias\", %\"unet.convs.3.norm1.running_mean\", %\"unet.convs.3.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             73 |  # node_Relu_73\n",
       "                   %\"relu_12\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_36\")\n",
       "             74 |  # node_Conv_74\n",
       "                   %\"conv2d_15\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_12\", %\"unet.convs.3.conv1.conv.weight\", %\"unet.convs.3.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             75 |  # node_Constant_75\n",
       "                   %\"val_45\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             76 |  # node_Resize_76\n",
       "                   %\"upsample_bilinear2d_6\"<FLOAT,[1,64,124,92]> ⬅️ ::Resize(%\"conv2d_15\", None, %\"val_45\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             77 |  # node_Constant_77\n",
       "                   %\"val_46\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             78 |  # node_Resize_78\n",
       "                   %\"upsample_bilinear2d_7\"<FLOAT,[1,64,124,92]> ⬅️ ::Resize(%\"add_5\", None, %\"val_46\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "             79 |  # node_Constant_79\n",
       "                   %\"val_47\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             80 |  # node__aten_native_batch_norm_inference_onnx_80\n",
       "                   %\"getitem_39\"<FLOAT,[1,64,124,92]>, %\"_native_batch_norm_legit_no_training_13__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_13__2\"<FLOAT,[64]>, %\"val_48\"<?,?>, %\"val_49\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_6\", %\"unet.convs.3.norm2.weight\", %\"unet.convs.3.norm2.bias\", %\"unet.convs.3.norm2.running_mean\", %\"unet.convs.3.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             81 |  # node_Relu_81\n",
       "                   %\"relu_13\"<FLOAT,[1,64,124,92]> ⬅️ ::Relu(%\"getitem_39\")\n",
       "             82 |  # node_Conv_82\n",
       "                   %\"conv2d_16\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_13\", %\"unet.convs.3.conv2.conv.weight\", %\"unet.convs.3.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             83 |  # node_Conv_83\n",
       "                   %\"conv2d_17\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"upsample_bilinear2d_7\", %\"unet.convs.3.conv3.conv.weight\", %\"unet.convs.3.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "             84 |  # node_Add_84\n",
       "                   %\"add_6\"<FLOAT,[1,128,124,92]> ⬅️ ::Add(%\"conv2d_17\", %\"conv2d_16\")\n",
       "             85 |  # node_Constant_85\n",
       "                   %\"val_50\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             86 |  # node__aten_native_batch_norm_inference_onnx_86\n",
       "                   %\"getitem_42\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_14__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_14__2\"<FLOAT,[128]>, %\"val_51\"<?,?>, %\"val_52\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_6\", %\"unet.convs_res.3.layers.0.norm1.weight\", %\"unet.convs_res.3.layers.0.norm1.bias\", %\"unet.convs_res.3.layers.0.norm1.running_mean\", %\"unet.convs_res.3.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             87 |  # node_Relu_87\n",
       "                   %\"relu_14\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_42\")\n",
       "             88 |  # node_Conv_88\n",
       "                   %\"conv2d_18\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_14\", %\"unet.convs_res.3.layers.0.conv1.conv.weight\", %\"unet.convs_res.3.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             89 |  # node_Constant_89\n",
       "                   %\"val_53\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             90 |  # node__aten_native_batch_norm_inference_onnx_90\n",
       "                   %\"getitem_45\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_15__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_15__2\"<FLOAT,[128]>, %\"val_54\"<?,?>, %\"val_55\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_18\", %\"unet.convs_res.3.layers.0.norm2.weight\", %\"unet.convs_res.3.layers.0.norm2.bias\", %\"unet.convs_res.3.layers.0.norm2.running_mean\", %\"unet.convs_res.3.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             91 |  # node_Relu_91\n",
       "                   %\"relu_15\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_45\")\n",
       "             92 |  # node_Conv_92\n",
       "                   %\"conv2d_19\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_15\", %\"unet.convs_res.3.layers.0.conv2.conv.weight\", %\"unet.convs_res.3.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             93 |  # node_Add_93\n",
       "                   %\"add_7\"<FLOAT,[1,128,124,92]> ⬅️ ::Add(%\"add_6\", %\"conv2d_19\")\n",
       "             94 |  # node_Constant_94\n",
       "                   %\"val_56\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "             95 |  # node__aten_native_batch_norm_inference_onnx_95\n",
       "                   %\"getitem_48\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_16__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_16__2\"<FLOAT,[128]>, %\"val_57\"<?,?>, %\"val_58\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_7\", %\"unet.convs.4.norm1.weight\", %\"unet.convs.4.norm1.bias\", %\"unet.convs.4.norm1.running_mean\", %\"unet.convs.4.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "             96 |  # node_Relu_96\n",
       "                   %\"relu_16\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_48\")\n",
       "             97 |  # node_Conv_97\n",
       "                   %\"conv2d_20\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_16\", %\"unet.convs.4.conv1.conv.weight\", %\"unet.convs.4.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "             98 |  # node_Constant_98\n",
       "                   %\"val_59\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "             99 |  # node_Resize_99\n",
       "                   %\"upsample_bilinear2d_8\"<FLOAT,[1,128,62,46]> ⬅️ ::Resize(%\"conv2d_20\", None, %\"val_59\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            100 |  # node_Constant_100\n",
       "                   %\"val_60\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 0.5, 0.5]}\n",
       "            101 |  # node_Resize_101\n",
       "                   %\"upsample_bilinear2d_9\"<FLOAT,[1,128,62,46]> ⬅️ ::Resize(%\"add_7\", None, %\"val_60\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            102 |  # node_Constant_102\n",
       "                   %\"val_61\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            103 |  # node__aten_native_batch_norm_inference_onnx_103\n",
       "                   %\"getitem_51\"<FLOAT,[1,128,62,46]>, %\"_native_batch_norm_legit_no_training_17__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_17__2\"<FLOAT,[128]>, %\"val_62\"<?,?>, %\"val_63\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_8\", %\"unet.convs.4.norm2.weight\", %\"unet.convs.4.norm2.bias\", %\"unet.convs.4.norm2.running_mean\", %\"unet.convs.4.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            104 |  # node_Relu_104\n",
       "                   %\"relu_17\"<FLOAT,[1,128,62,46]> ⬅️ ::Relu(%\"getitem_51\")\n",
       "            105 |  # node_Conv_105\n",
       "                   %\"conv2d_21\"<FLOAT,[1,256,62,46]> ⬅️ ::Conv(%\"relu_17\", %\"unet.convs.4.conv2.conv.weight\", %\"unet.convs.4.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            106 |  # node_Conv_106\n",
       "                   %\"conv2d_22\"<FLOAT,[1,256,62,46]> ⬅️ ::Conv(%\"upsample_bilinear2d_9\", %\"unet.convs.4.conv3.conv.weight\", %\"unet.convs.4.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "            107 |  # node_Add_107\n",
       "                   %\"add_8\"<FLOAT,[1,256,62,46]> ⬅️ ::Add(%\"conv2d_22\", %\"conv2d_21\")\n",
       "            108 |  # node_Constant_108\n",
       "                   %\"val_64\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            109 |  # node__aten_native_batch_norm_inference_onnx_109\n",
       "                   %\"getitem_54\"<FLOAT,[1,256,62,46]>, %\"_native_batch_norm_legit_no_training_18__1\"<FLOAT,[256]>, %\"_native_batch_norm_legit_no_training_18__2\"<FLOAT,[256]>, %\"val_65\"<?,?>, %\"val_66\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_8\", %\"unet.convs_res.4.layers.0.norm1.weight\", %\"unet.convs_res.4.layers.0.norm1.bias\", %\"unet.convs_res.4.layers.0.norm1.running_mean\", %\"unet.convs_res.4.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            110 |  # node_Relu_110\n",
       "                   %\"relu_18\"<FLOAT,[1,256,62,46]> ⬅️ ::Relu(%\"getitem_54\")\n",
       "            111 |  # node_Conv_111\n",
       "                   %\"conv2d_23\"<FLOAT,[1,256,62,46]> ⬅️ ::Conv(%\"relu_18\", %\"unet.convs_res.4.layers.0.conv1.conv.weight\", %\"unet.convs_res.4.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            112 |  # node_Constant_112\n",
       "                   %\"val_67\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            113 |  # node__aten_native_batch_norm_inference_onnx_113\n",
       "                   %\"getitem_57\"<FLOAT,[1,256,62,46]>, %\"_native_batch_norm_legit_no_training_19__1\"<FLOAT,[256]>, %\"_native_batch_norm_legit_no_training_19__2\"<FLOAT,[256]>, %\"val_68\"<?,?>, %\"val_69\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_23\", %\"unet.convs_res.4.layers.0.norm2.weight\", %\"unet.convs_res.4.layers.0.norm2.bias\", %\"unet.convs_res.4.layers.0.norm2.running_mean\", %\"unet.convs_res.4.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            114 |  # node_Relu_114\n",
       "                   %\"relu_19\"<FLOAT,[1,256,62,46]> ⬅️ ::Relu(%\"getitem_57\")\n",
       "            115 |  # node_Conv_115\n",
       "                   %\"conv2d_24\"<FLOAT,[1,256,62,46]> ⬅️ ::Conv(%\"relu_19\", %\"unet.convs_res.4.layers.0.conv2.conv.weight\", %\"unet.convs_res.4.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            116 |  # node_Add_116\n",
       "                   %\"add_9\"<FLOAT,[1,256,62,46]> ⬅️ ::Add(%\"add_8\", %\"conv2d_24\")\n",
       "            117 |  # node_Constant_117\n",
       "                   %\"val_70\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            118 |  # node__aten_native_batch_norm_inference_onnx_118\n",
       "                   %\"getitem_60\"<FLOAT,[1,256,62,46]>, %\"_native_batch_norm_legit_no_training_20__1\"<FLOAT,[256]>, %\"_native_batch_norm_legit_no_training_20__2\"<FLOAT,[256]>, %\"val_71\"<?,?>, %\"val_72\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_9\", %\"unet.convts.0.norm1.weight\", %\"unet.convts.0.norm1.bias\", %\"unet.convts.0.norm1.running_mean\", %\"unet.convts.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            119 |  # node_Relu_119\n",
       "                   %\"relu_20\"<FLOAT,[1,256,62,46]> ⬅️ ::Relu(%\"getitem_60\")\n",
       "            120 |  # node_Conv_120\n",
       "                   %\"conv2d_25\"<FLOAT,[1,256,62,46]> ⬅️ ::Conv(%\"relu_20\", %\"unet.convts.0.conv1.conv.weight\", %\"unet.convts.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            121 |  # node_Constant_121\n",
       "                   %\"val_73\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            122 |  # node_Resize_122\n",
       "                   %\"upsample_bilinear2d_10\"<FLOAT,[1,256,124,92]> ⬅️ ::Resize(%\"conv2d_25\", None, %\"val_73\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            123 |  # node_Constant_123\n",
       "                   %\"val_74\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            124 |  # node_Resize_124\n",
       "                   %\"upsample_bilinear2d_11\"<FLOAT,[1,256,124,92]> ⬅️ ::Resize(%\"add_9\", None, %\"val_74\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            125 |  # node_Constant_125\n",
       "                   %\"val_75\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            126 |  # node__aten_native_batch_norm_inference_onnx_126\n",
       "                   %\"getitem_63\"<FLOAT,[1,256,124,92]>, %\"_native_batch_norm_legit_no_training_21__1\"<FLOAT,[256]>, %\"_native_batch_norm_legit_no_training_21__2\"<FLOAT,[256]>, %\"val_76\"<?,?>, %\"val_77\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_10\", %\"unet.convts.0.norm2.weight\", %\"unet.convts.0.norm2.bias\", %\"unet.convts.0.norm2.running_mean\", %\"unet.convts.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            127 |  # node_Relu_127\n",
       "                   %\"relu_21\"<FLOAT,[1,256,124,92]> ⬅️ ::Relu(%\"getitem_63\")\n",
       "            128 |  # node_Conv_128\n",
       "                   %\"conv2d_26\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_21\", %\"unet.convts.0.conv2.conv.weight\", %\"unet.convts.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            129 |  # node_Conv_129\n",
       "                   %\"conv2d_27\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"upsample_bilinear2d_11\", %\"unet.convts.0.conv3.conv.weight\", %\"unet.convts.0.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "            130 |  # node_Add_130\n",
       "                   %\"add_10\"<FLOAT,[1,128,124,92]> ⬅️ ::Add(%\"conv2d_27\", %\"conv2d_26\")\n",
       "            131 |  # node_Constant_131\n",
       "                   %\"val_78\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            132 |  # node__aten_native_batch_norm_inference_onnx_132\n",
       "                   %\"getitem_66\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_22__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_22__2\"<FLOAT,[128]>, %\"val_79\"<?,?>, %\"val_80\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_10\", %\"unet.convts_res.0.layers.0.norm1.weight\", %\"unet.convts_res.0.layers.0.norm1.bias\", %\"unet.convts_res.0.layers.0.norm1.running_mean\", %\"unet.convts_res.0.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            133 |  # node_Relu_133\n",
       "                   %\"relu_22\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_66\")\n",
       "            134 |  # node_Conv_134\n",
       "                   %\"conv2d_28\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_22\", %\"unet.convts_res.0.layers.0.conv1.conv.weight\", %\"unet.convts_res.0.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            135 |  # node_Constant_135\n",
       "                   %\"val_81\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            136 |  # node__aten_native_batch_norm_inference_onnx_136\n",
       "                   %\"getitem_69\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_23__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_23__2\"<FLOAT,[128]>, %\"val_82\"<?,?>, %\"val_83\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_28\", %\"unet.convts_res.0.layers.0.norm2.weight\", %\"unet.convts_res.0.layers.0.norm2.bias\", %\"unet.convts_res.0.layers.0.norm2.running_mean\", %\"unet.convts_res.0.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            137 |  # node_Relu_137\n",
       "                   %\"relu_23\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_69\")\n",
       "            138 |  # node_Conv_138\n",
       "                   %\"conv2d_29\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_23\", %\"unet.convts_res.0.layers.0.conv2.conv.weight\", %\"unet.convts_res.0.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            139 |  # node_Add_139\n",
       "                   %\"add_11\"<FLOAT,[1,128,124,92]> ⬅️ ::Add(%\"add_10\", %\"conv2d_29\")\n",
       "            140 |  # node_Constant_140\n",
       "                   %\"val_84\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            141 |  # node__aten_native_batch_norm_inference_onnx_141\n",
       "                   %\"getitem_72\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_24__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_24__2\"<FLOAT,[128]>, %\"val_85\"<?,?>, %\"val_86\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_7\", %\"unet.links.0.layers.0.norm1.weight\", %\"unet.links.0.layers.0.norm1.bias\", %\"unet.links.0.layers.0.norm1.running_mean\", %\"unet.links.0.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            142 |  # node_Relu_142\n",
       "                   %\"relu_24\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_72\")\n",
       "            143 |  # node_Conv_143\n",
       "                   %\"conv2d_30\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_24\", %\"unet.links.0.layers.0.conv1.conv.weight\", %\"unet.links.0.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            144 |  # node_Constant_144\n",
       "                   %\"val_87\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            145 |  # node__aten_native_batch_norm_inference_onnx_145\n",
       "                   %\"getitem_75\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_25__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_25__2\"<FLOAT,[128]>, %\"val_88\"<?,?>, %\"val_89\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_30\", %\"unet.links.0.layers.0.norm2.weight\", %\"unet.links.0.layers.0.norm2.bias\", %\"unet.links.0.layers.0.norm2.running_mean\", %\"unet.links.0.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            146 |  # node_Relu_146\n",
       "                   %\"relu_25\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_75\")\n",
       "            147 |  # node_Conv_147\n",
       "                   %\"conv2d_31\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_25\", %\"unet.links.0.layers.0.conv2.conv.weight\", %\"unet.links.0.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            148 |  # node_Add_148\n",
       "                   %\"add_12\"<FLOAT,[1,128,124,92]> ⬅️ ::Add(%\"add_7\", %\"conv2d_31\")\n",
       "            149 |  # node_Add_149\n",
       "                   %\"add_13\"<FLOAT,[1,128,124,92]> ⬅️ ::Add(%\"add_11\", %\"add_12\")\n",
       "            150 |  # node_Constant_150\n",
       "                   %\"val_90\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            151 |  # node__aten_native_batch_norm_inference_onnx_151\n",
       "                   %\"getitem_78\"<FLOAT,[1,128,124,92]>, %\"_native_batch_norm_legit_no_training_26__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_26__2\"<FLOAT,[128]>, %\"val_91\"<?,?>, %\"val_92\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_13\", %\"unet.convts.1.norm1.weight\", %\"unet.convts.1.norm1.bias\", %\"unet.convts.1.norm1.running_mean\", %\"unet.convts.1.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            152 |  # node_Relu_152\n",
       "                   %\"relu_26\"<FLOAT,[1,128,124,92]> ⬅️ ::Relu(%\"getitem_78\")\n",
       "            153 |  # node_Conv_153\n",
       "                   %\"conv2d_32\"<FLOAT,[1,128,124,92]> ⬅️ ::Conv(%\"relu_26\", %\"unet.convts.1.conv1.conv.weight\", %\"unet.convts.1.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            154 |  # node_Constant_154\n",
       "                   %\"val_93\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            155 |  # node_Resize_155\n",
       "                   %\"upsample_bilinear2d_12\"<FLOAT,[1,128,248,184]> ⬅️ ::Resize(%\"conv2d_32\", None, %\"val_93\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            156 |  # node_Constant_156\n",
       "                   %\"val_94\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            157 |  # node_Resize_157\n",
       "                   %\"upsample_bilinear2d_13\"<FLOAT,[1,128,248,184]> ⬅️ ::Resize(%\"add_13\", None, %\"val_94\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            158 |  # node_Constant_158\n",
       "                   %\"val_95\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            159 |  # node__aten_native_batch_norm_inference_onnx_159\n",
       "                   %\"getitem_81\"<FLOAT,[1,128,248,184]>, %\"_native_batch_norm_legit_no_training_27__1\"<FLOAT,[128]>, %\"_native_batch_norm_legit_no_training_27__2\"<FLOAT,[128]>, %\"val_96\"<?,?>, %\"val_97\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_12\", %\"unet.convts.1.norm2.weight\", %\"unet.convts.1.norm2.bias\", %\"unet.convts.1.norm2.running_mean\", %\"unet.convts.1.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            160 |  # node_Relu_160\n",
       "                   %\"relu_27\"<FLOAT,[1,128,248,184]> ⬅️ ::Relu(%\"getitem_81\")\n",
       "            161 |  # node_Conv_161\n",
       "                   %\"conv2d_33\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_27\", %\"unet.convts.1.conv2.conv.weight\", %\"unet.convts.1.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            162 |  # node_Conv_162\n",
       "                   %\"conv2d_34\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"upsample_bilinear2d_13\", %\"unet.convts.1.conv3.conv.weight\", %\"unet.convts.1.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "            163 |  # node_Add_163\n",
       "                   %\"add_14\"<FLOAT,[1,64,248,184]> ⬅️ ::Add(%\"conv2d_34\", %\"conv2d_33\")\n",
       "            164 |  # node_Constant_164\n",
       "                   %\"val_98\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            165 |  # node__aten_native_batch_norm_inference_onnx_165\n",
       "                   %\"getitem_84\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_28__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_28__2\"<FLOAT,[64]>, %\"val_99\"<?,?>, %\"val_100\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_14\", %\"unet.convts_res.1.layers.0.norm1.weight\", %\"unet.convts_res.1.layers.0.norm1.bias\", %\"unet.convts_res.1.layers.0.norm1.running_mean\", %\"unet.convts_res.1.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            166 |  # node_Relu_166\n",
       "                   %\"relu_28\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_84\")\n",
       "            167 |  # node_Conv_167\n",
       "                   %\"conv2d_35\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_28\", %\"unet.convts_res.1.layers.0.conv1.conv.weight\", %\"unet.convts_res.1.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            168 |  # node_Constant_168\n",
       "                   %\"val_101\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            169 |  # node__aten_native_batch_norm_inference_onnx_169\n",
       "                   %\"getitem_87\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_29__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_29__2\"<FLOAT,[64]>, %\"val_102\"<?,?>, %\"val_103\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_35\", %\"unet.convts_res.1.layers.0.norm2.weight\", %\"unet.convts_res.1.layers.0.norm2.bias\", %\"unet.convts_res.1.layers.0.norm2.running_mean\", %\"unet.convts_res.1.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            170 |  # node_Relu_170\n",
       "                   %\"relu_29\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_87\")\n",
       "            171 |  # node_Conv_171\n",
       "                   %\"conv2d_36\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_29\", %\"unet.convts_res.1.layers.0.conv2.conv.weight\", %\"unet.convts_res.1.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            172 |  # node_Add_172\n",
       "                   %\"add_15\"<FLOAT,[1,64,248,184]> ⬅️ ::Add(%\"add_14\", %\"conv2d_36\")\n",
       "            173 |  # node_Constant_173\n",
       "                   %\"val_104\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            174 |  # node__aten_native_batch_norm_inference_onnx_174\n",
       "                   %\"getitem_90\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_30__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_30__2\"<FLOAT,[64]>, %\"val_105\"<?,?>, %\"val_106\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_5\", %\"unet.links.1.layers.0.norm1.weight\", %\"unet.links.1.layers.0.norm1.bias\", %\"unet.links.1.layers.0.norm1.running_mean\", %\"unet.links.1.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            175 |  # node_Relu_175\n",
       "                   %\"relu_30\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_90\")\n",
       "            176 |  # node_Conv_176\n",
       "                   %\"conv2d_37\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_30\", %\"unet.links.1.layers.0.conv1.conv.weight\", %\"unet.links.1.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            177 |  # node_Constant_177\n",
       "                   %\"val_107\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            178 |  # node__aten_native_batch_norm_inference_onnx_178\n",
       "                   %\"getitem_93\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_31__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_31__2\"<FLOAT,[64]>, %\"val_108\"<?,?>, %\"val_109\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_37\", %\"unet.links.1.layers.0.norm2.weight\", %\"unet.links.1.layers.0.norm2.bias\", %\"unet.links.1.layers.0.norm2.running_mean\", %\"unet.links.1.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            179 |  # node_Relu_179\n",
       "                   %\"relu_31\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_93\")\n",
       "            180 |  # node_Conv_180\n",
       "                   %\"conv2d_38\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_31\", %\"unet.links.1.layers.0.conv2.conv.weight\", %\"unet.links.1.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            181 |  # node_Add_181\n",
       "                   %\"add_16\"<FLOAT,[1,64,248,184]> ⬅️ ::Add(%\"add_5\", %\"conv2d_38\")\n",
       "            182 |  # node_Add_182\n",
       "                   %\"add_17\"<FLOAT,[1,64,248,184]> ⬅️ ::Add(%\"add_15\", %\"add_16\")\n",
       "            183 |  # node_Constant_183\n",
       "                   %\"val_110\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            184 |  # node__aten_native_batch_norm_inference_onnx_184\n",
       "                   %\"getitem_96\"<FLOAT,[1,64,248,184]>, %\"_native_batch_norm_legit_no_training_32__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_32__2\"<FLOAT,[64]>, %\"val_111\"<?,?>, %\"val_112\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_17\", %\"unet.convts.2.norm1.weight\", %\"unet.convts.2.norm1.bias\", %\"unet.convts.2.norm1.running_mean\", %\"unet.convts.2.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            185 |  # node_Relu_185\n",
       "                   %\"relu_32\"<FLOAT,[1,64,248,184]> ⬅️ ::Relu(%\"getitem_96\")\n",
       "            186 |  # node_Conv_186\n",
       "                   %\"conv2d_39\"<FLOAT,[1,64,248,184]> ⬅️ ::Conv(%\"relu_32\", %\"unet.convts.2.conv1.conv.weight\", %\"unet.convts.2.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            187 |  # node_Constant_187\n",
       "                   %\"val_113\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            188 |  # node_Resize_188\n",
       "                   %\"upsample_bilinear2d_14\"<FLOAT,[1,64,496,368]> ⬅️ ::Resize(%\"conv2d_39\", None, %\"val_113\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            189 |  # node_Constant_189\n",
       "                   %\"val_114\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            190 |  # node_Resize_190\n",
       "                   %\"upsample_bilinear2d_15\"<FLOAT,[1,64,496,368]> ⬅️ ::Resize(%\"add_17\", None, %\"val_114\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            191 |  # node_Constant_191\n",
       "                   %\"val_115\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            192 |  # node__aten_native_batch_norm_inference_onnx_192\n",
       "                   %\"getitem_99\"<FLOAT,[1,64,496,368]>, %\"_native_batch_norm_legit_no_training_33__1\"<FLOAT,[64]>, %\"_native_batch_norm_legit_no_training_33__2\"<FLOAT,[64]>, %\"val_116\"<?,?>, %\"val_117\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_14\", %\"unet.convts.2.norm2.weight\", %\"unet.convts.2.norm2.bias\", %\"unet.convts.2.norm2.running_mean\", %\"unet.convts.2.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            193 |  # node_Relu_193\n",
       "                   %\"relu_33\"<FLOAT,[1,64,496,368]> ⬅️ ::Relu(%\"getitem_99\")\n",
       "            194 |  # node_Conv_194\n",
       "                   %\"conv2d_40\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_33\", %\"unet.convts.2.conv2.conv.weight\", %\"unet.convts.2.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            195 |  # node_Conv_195\n",
       "                   %\"conv2d_41\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"upsample_bilinear2d_15\", %\"unet.convts.2.conv3.conv.weight\", %\"unet.convts.2.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "            196 |  # node_Add_196\n",
       "                   %\"add_18\"<FLOAT,[1,32,496,368]> ⬅️ ::Add(%\"conv2d_41\", %\"conv2d_40\")\n",
       "            197 |  # node_Constant_197\n",
       "                   %\"val_118\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            198 |  # node__aten_native_batch_norm_inference_onnx_198\n",
       "                   %\"getitem_102\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_34__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_34__2\"<FLOAT,[32]>, %\"val_119\"<?,?>, %\"val_120\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_18\", %\"unet.convts_res.2.layers.0.norm1.weight\", %\"unet.convts_res.2.layers.0.norm1.bias\", %\"unet.convts_res.2.layers.0.norm1.running_mean\", %\"unet.convts_res.2.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            199 |  # node_Relu_199\n",
       "                   %\"relu_34\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_102\")\n",
       "            200 |  # node_Conv_200\n",
       "                   %\"conv2d_42\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_34\", %\"unet.convts_res.2.layers.0.conv1.conv.weight\", %\"unet.convts_res.2.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            201 |  # node_Constant_201\n",
       "                   %\"val_121\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            202 |  # node__aten_native_batch_norm_inference_onnx_202\n",
       "                   %\"getitem_105\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_35__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_35__2\"<FLOAT,[32]>, %\"val_122\"<?,?>, %\"val_123\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_42\", %\"unet.convts_res.2.layers.0.norm2.weight\", %\"unet.convts_res.2.layers.0.norm2.bias\", %\"unet.convts_res.2.layers.0.norm2.running_mean\", %\"unet.convts_res.2.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            203 |  # node_Relu_203\n",
       "                   %\"relu_35\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_105\")\n",
       "            204 |  # node_Conv_204\n",
       "                   %\"conv2d_43\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_35\", %\"unet.convts_res.2.layers.0.conv2.conv.weight\", %\"unet.convts_res.2.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            205 |  # node_Add_205\n",
       "                   %\"add_19\"<FLOAT,[1,32,496,368]> ⬅️ ::Add(%\"add_18\", %\"conv2d_43\")\n",
       "            206 |  # node_Constant_206\n",
       "                   %\"val_124\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            207 |  # node__aten_native_batch_norm_inference_onnx_207\n",
       "                   %\"getitem_108\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_36__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_36__2\"<FLOAT,[32]>, %\"val_125\"<?,?>, %\"val_126\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_3\", %\"unet.links.2.layers.0.norm1.weight\", %\"unet.links.2.layers.0.norm1.bias\", %\"unet.links.2.layers.0.norm1.running_mean\", %\"unet.links.2.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            208 |  # node_Relu_208\n",
       "                   %\"relu_36\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_108\")\n",
       "            209 |  # node_Conv_209\n",
       "                   %\"conv2d_44\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_36\", %\"unet.links.2.layers.0.conv1.conv.weight\", %\"unet.links.2.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            210 |  # node_Constant_210\n",
       "                   %\"val_127\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            211 |  # node__aten_native_batch_norm_inference_onnx_211\n",
       "                   %\"getitem_111\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_37__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_37__2\"<FLOAT,[32]>, %\"val_128\"<?,?>, %\"val_129\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_44\", %\"unet.links.2.layers.0.norm2.weight\", %\"unet.links.2.layers.0.norm2.bias\", %\"unet.links.2.layers.0.norm2.running_mean\", %\"unet.links.2.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            212 |  # node_Relu_212\n",
       "                   %\"relu_37\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_111\")\n",
       "            213 |  # node_Conv_213\n",
       "                   %\"conv2d_45\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_37\", %\"unet.links.2.layers.0.conv2.conv.weight\", %\"unet.links.2.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            214 |  # node_Add_214\n",
       "                   %\"add_20\"<FLOAT,[1,32,496,368]> ⬅️ ::Add(%\"add_3\", %\"conv2d_45\")\n",
       "            215 |  # node_Add_215\n",
       "                   %\"add_21\"<FLOAT,[1,32,496,368]> ⬅️ ::Add(%\"add_19\", %\"add_20\")\n",
       "            216 |  # node_Constant_216\n",
       "                   %\"val_130\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            217 |  # node__aten_native_batch_norm_inference_onnx_217\n",
       "                   %\"getitem_114\"<FLOAT,[1,32,496,368]>, %\"_native_batch_norm_legit_no_training_38__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_38__2\"<FLOAT,[32]>, %\"val_131\"<?,?>, %\"val_132\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_21\", %\"unet.convts.3.norm1.weight\", %\"unet.convts.3.norm1.bias\", %\"unet.convts.3.norm1.running_mean\", %\"unet.convts.3.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            218 |  # node_Relu_218\n",
       "                   %\"relu_38\"<FLOAT,[1,32,496,368]> ⬅️ ::Relu(%\"getitem_114\")\n",
       "            219 |  # node_Conv_219\n",
       "                   %\"conv2d_46\"<FLOAT,[1,32,496,368]> ⬅️ ::Conv(%\"relu_38\", %\"unet.convts.3.conv1.conv.weight\", %\"unet.convts.3.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            220 |  # node_Constant_220\n",
       "                   %\"val_133\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            221 |  # node_Resize_221\n",
       "                   %\"upsample_bilinear2d_16\"<FLOAT,[1,32,992,736]> ⬅️ ::Resize(%\"conv2d_46\", None, %\"val_133\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            222 |  # node_Constant_222\n",
       "                   %\"val_134\"<?,?> ⬅️ ::Constant() {value_floats=[1.0, 1.0, 2.0, 2.0]}\n",
       "            223 |  # node_Resize_223\n",
       "                   %\"upsample_bilinear2d_17\"<FLOAT,[1,32,992,736]> ⬅️ ::Resize(%\"add_21\", None, %\"val_134\") {antialias=0, coordinate_transformation_mode=pytorch_half_pixel, cubic_coeff_a=-0.75, exclude_outside=0, extrapolation_value=0.0, keep_aspect_ratio_policy=stretch, mode=linear, nearest_mode=floor}\n",
       "            224 |  # node_Constant_224\n",
       "                   %\"val_135\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            225 |  # node__aten_native_batch_norm_inference_onnx_225\n",
       "                   %\"getitem_117\"<FLOAT,[1,32,992,736]>, %\"_native_batch_norm_legit_no_training_39__1\"<FLOAT,[32]>, %\"_native_batch_norm_legit_no_training_39__2\"<FLOAT,[32]>, %\"val_136\"<?,?>, %\"val_137\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"upsample_bilinear2d_16\", %\"unet.convts.3.norm2.weight\", %\"unet.convts.3.norm2.bias\", %\"unet.convts.3.norm2.running_mean\", %\"unet.convts.3.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            226 |  # node_Relu_226\n",
       "                   %\"relu_39\"<FLOAT,[1,32,992,736]> ⬅️ ::Relu(%\"getitem_117\")\n",
       "            227 |  # node_Conv_227\n",
       "                   %\"conv2d_47\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_39\", %\"unet.convts.3.conv2.conv.weight\", %\"unet.convts.3.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            228 |  # node_Conv_228\n",
       "                   %\"conv2d_48\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"upsample_bilinear2d_17\", %\"unet.convts.3.conv3.conv.weight\", %\"unet.convts.3.conv3.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[0, 0, 0, 0], strides=[1, 1]}\n",
       "            229 |  # node_Add_229\n",
       "                   %\"add_22\"<FLOAT,[1,16,992,736]> ⬅️ ::Add(%\"conv2d_48\", %\"conv2d_47\")\n",
       "            230 |  # node_Constant_230\n",
       "                   %\"val_138\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            231 |  # node__aten_native_batch_norm_inference_onnx_231\n",
       "                   %\"getitem_120\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_40__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_40__2\"<FLOAT,[16]>, %\"val_139\"<?,?>, %\"val_140\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_22\", %\"unet.convts_res.3.layers.0.norm1.weight\", %\"unet.convts_res.3.layers.0.norm1.bias\", %\"unet.convts_res.3.layers.0.norm1.running_mean\", %\"unet.convts_res.3.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            232 |  # node_Relu_232\n",
       "                   %\"relu_40\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_120\")\n",
       "            233 |  # node_Conv_233\n",
       "                   %\"conv2d_49\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_40\", %\"unet.convts_res.3.layers.0.conv1.conv.weight\", %\"unet.convts_res.3.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            234 |  # node_Constant_234\n",
       "                   %\"val_141\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            235 |  # node__aten_native_batch_norm_inference_onnx_235\n",
       "                   %\"getitem_123\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_41__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_41__2\"<FLOAT,[16]>, %\"val_142\"<?,?>, %\"val_143\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_49\", %\"unet.convts_res.3.layers.0.norm2.weight\", %\"unet.convts_res.3.layers.0.norm2.bias\", %\"unet.convts_res.3.layers.0.norm2.running_mean\", %\"unet.convts_res.3.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            236 |  # node_Relu_236\n",
       "                   %\"relu_41\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_123\")\n",
       "            237 |  # node_Conv_237\n",
       "                   %\"conv2d_50\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_41\", %\"unet.convts_res.3.layers.0.conv2.conv.weight\", %\"unet.convts_res.3.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            238 |  # node_Add_238\n",
       "                   %\"add_23\"<FLOAT,[1,16,992,736]> ⬅️ ::Add(%\"add_22\", %\"conv2d_50\")\n",
       "            239 |  # node_Constant_239\n",
       "                   %\"val_144\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            240 |  # node__aten_native_batch_norm_inference_onnx_240\n",
       "                   %\"getitem_126\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_42__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_42__2\"<FLOAT,[16]>, %\"val_145\"<?,?>, %\"val_146\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"add_1\", %\"unet.links.3.layers.0.norm1.weight\", %\"unet.links.3.layers.0.norm1.bias\", %\"unet.links.3.layers.0.norm1.running_mean\", %\"unet.links.3.layers.0.norm1.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            241 |  # node_Relu_241\n",
       "                   %\"relu_42\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_126\")\n",
       "            242 |  # node_Conv_242\n",
       "                   %\"conv2d_51\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_42\", %\"unet.links.3.layers.0.conv1.conv.weight\", %\"unet.links.3.layers.0.conv1.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            243 |  # node_Constant_243\n",
       "                   %\"val_147\"<?,?> ⬅️ ::Constant() {value_ints=[0, 2, 3]}\n",
       "            244 |  # node__aten_native_batch_norm_inference_onnx_244\n",
       "                   %\"getitem_129\"<FLOAT,[1,16,992,736]>, %\"_native_batch_norm_legit_no_training_43__1\"<FLOAT,[16]>, %\"_native_batch_norm_legit_no_training_43__2\"<FLOAT,[16]>, %\"val_148\"<?,?>, %\"val_149\"<?,?> ⬅️ pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(%\"conv2d_51\", %\"unet.links.3.layers.0.norm2.weight\", %\"unet.links.3.layers.0.norm2.bias\", %\"unet.links.3.layers.0.norm2.running_mean\", %\"unet.links.3.layers.0.norm2.running_var\") {momentum=0.99, eps=1e-05}\n",
       "            245 |  # node_Relu_245\n",
       "                   %\"relu_43\"<FLOAT,[1,16,992,736]> ⬅️ ::Relu(%\"getitem_129\")\n",
       "            246 |  # node_Conv_246\n",
       "                   %\"conv2d_52\"<FLOAT,[1,16,992,736]> ⬅️ ::Conv(%\"relu_43\", %\"unet.links.3.layers.0.conv2.conv.weight\", %\"unet.links.3.layers.0.conv2.conv.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, pads=[1, 1, 1, 1], strides=[1, 1]}\n",
       "            247 |  # node_Add_247\n",
       "                   %\"add_24\"<FLOAT,[1,16,992,736]> ⬅️ ::Add(%\"add_1\", %\"conv2d_52\")\n",
       "            248 |  # node_Add_248\n",
       "                   %\"add_25\"<FLOAT,[1,16,992,736]> ⬅️ ::Add(%\"add_23\", %\"add_24\")\n",
       "            249 |  # node_ConvTranspose_249\n",
       "                   %\"convolution\"<FLOAT,[1,3,1984,1472]> ⬅️ ::ConvTranspose(%\"add_25\", %\"convT_o1.weight\", %\"convT_o1.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, output_padding=[1, 1], pads=[1, 1, 1, 1], strides=[2, 2]}\n",
       "            250 |  # node_ConvTranspose_250\n",
       "                   %\"output_pretil\"<FLOAT,[1,1,1984,1472]> ⬅️ ::ConvTranspose(%\"add_25\", %\"convT_o2.weight\", %\"convT_o2.bias\") {auto_pad=NOTSET, dilations=[1, 1], group=1, output_padding=[1, 1], pads=[1, 1, 1, 1], strides=[2, 2]}\n",
       "            251 |  # node_Softmax_251\n",
       "                   %\"output_class\"<FLOAT,[1,3,1984,1472]> ⬅️ ::Softmax(%\"convolution\") {axis=1}\n",
       "            return %\"output_class\"<FLOAT,[1,3,1984,1472]>, %\"output_pretil\"<FLOAT,[1,1,1984,1472]>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib::_aten_native_batch_norm_inference_onnx(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>,\n",
       "                %\"weight\"<?,?>,\n",
       "                %\"bias\"<?,?>,\n",
       "                %\"running_mean\"<?,?>,\n",
       "                %\"running_var\"<?,?>\n",
       "            ),\n",
       "            attributes={\n",
       "                momentum: UNDEFINED,\n",
       "                eps: UNDEFINED\n",
       "            }\n",
       "            outputs=(\n",
       "                %\"norm\"<?,?>,\n",
       "                %\"running_mean_fp32\"<?,?>,\n",
       "                %\"invstd_1\"<?,?>,\n",
       "                %\"return_val3\"<?,?>,\n",
       "                %\"return_val4\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # n0\n",
       "                  %\"norm\"<?,?> ⬅️ ::BatchNormalization(%\"input\", %\"weight\", %\"bias\", %\"running_mean\", %\"running_var\") {epsilon=RefAttr('epsilon', FLOAT, ref_attr_name='eps'), momentum=RefAttr('momentum', FLOAT, ref_attr_name='momentum'), training_mode=0}\n",
       "             1 |  # n1\n",
       "                  %\"const\"<?,?> ⬅️ ::Constant() {value=TensorProtoTensor<FLOAT,[]>(name='const')}\n",
       "             2 |  # n2\n",
       "                  %\"eps\"<?,?> ⬅️ ::Constant() {value_float=RefAttr('value_float', FLOAT, ref_attr_name='eps')}\n",
       "             3 |  # n3\n",
       "                  %\"eps_cast\"<?,?> ⬅️ ::CastLike(%\"eps\", %\"running_var\")\n",
       "             4 |  # n4\n",
       "                  %\"tmp\"<?,?> ⬅️ ::Add(%\"running_var\", %\"eps_cast\")\n",
       "             5 |  # n5\n",
       "                  %\"tmp_0\"<?,?> ⬅️ ::Sqrt(%\"tmp\")\n",
       "             6 |  # n6\n",
       "                  %\"const_cast\"<?,?> ⬅️ ::CastLike(%\"const\", %\"tmp_0\")\n",
       "             7 |  # n7\n",
       "                  %\"invstd\"<?,?> ⬅️ ::Div(%\"const_cast\", %\"tmp_0\")\n",
       "             8 |  # n8\n",
       "                  %\"running_mean_fp32\"<?,?> ⬅️ ::Cast(%\"running_mean\") {to=1}\n",
       "             9 |  # n9\n",
       "                  %\"invstd_1\"<?,?> ⬅️ ::Cast(%\"invstd\") {to=1}\n",
       "            10 |  # n10\n",
       "                  %\"return_val3\"<?,?> ⬅️ ::Identity(%\"running_mean\")\n",
       "            11 |  # n11\n",
       "                  %\"return_val4\"<?,?> ⬅️ ::Identity(%\"running_var\")\n",
       "            return %\"norm\"<?,?>, %\"running_mean_fp32\"<?,?>, %\"invstd_1\"<?,?>, %\"return_val3\"<?,?>, %\"return_val4\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::Rank(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::IsScalar(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"tmp_0\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            2 |  # n2\n",
       "                 %\"tmp_1\"<?,?> ⬅️ ::Constant() {value_int=0}\n",
       "            3 |  # n3\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Equal(%\"tmp_0\", %\"tmp_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_unet_convs_0_norm1_weight: \"f32[1]\", p_unet_convs_0_norm1_bias: \"f32[1]\", p_unet_convs_0_conv1_conv_weight: \"f32[1, 1, 3, 3]\", p_unet_convs_0_conv1_conv_bias: \"f32[1]\", p_unet_convs_0_norm2_weight: \"f32[1]\", p_unet_convs_0_norm2_bias: \"f32[1]\", p_unet_convs_0_conv2_conv_weight: \"f32[16, 1, 3, 3]\", p_unet_convs_0_conv2_conv_bias: \"f32[16]\", p_unet_convs_0_conv3_conv_weight: \"f32[16, 1, 1, 1]\", p_unet_convs_0_conv3_conv_bias: \"f32[16]\", p_unet_convs_1_norm1_weight: \"f32[16]\", p_unet_convs_1_norm1_bias: \"f32[16]\", p_unet_convs_1_conv1_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_convs_1_conv1_conv_bias: \"f32[16]\", p_unet_convs_1_norm2_weight: \"f32[16]\", p_unet_convs_1_norm2_bias: \"f32[16]\", p_unet_convs_1_conv2_conv_weight: \"f32[32, 16, 3, 3]\", p_unet_convs_1_conv2_conv_bias: \"f32[32]\", p_unet_convs_1_conv3_conv_weight: \"f32[32, 16, 1, 1]\", p_unet_convs_1_conv3_conv_bias: \"f32[32]\", p_unet_convs_2_norm1_weight: \"f32[32]\", p_unet_convs_2_norm1_bias: \"f32[32]\", p_unet_convs_2_conv1_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_convs_2_conv1_conv_bias: \"f32[32]\", p_unet_convs_2_norm2_weight: \"f32[32]\", p_unet_convs_2_norm2_bias: \"f32[32]\", p_unet_convs_2_conv2_conv_weight: \"f32[64, 32, 3, 3]\", p_unet_convs_2_conv2_conv_bias: \"f32[64]\", p_unet_convs_2_conv3_conv_weight: \"f32[64, 32, 1, 1]\", p_unet_convs_2_conv3_conv_bias: \"f32[64]\", p_unet_convs_3_norm1_weight: \"f32[64]\", p_unet_convs_3_norm1_bias: \"f32[64]\", p_unet_convs_3_conv1_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_convs_3_conv1_conv_bias: \"f32[64]\", p_unet_convs_3_norm2_weight: \"f32[64]\", p_unet_convs_3_norm2_bias: \"f32[64]\", p_unet_convs_3_conv2_conv_weight: \"f32[128, 64, 3, 3]\", p_unet_convs_3_conv2_conv_bias: \"f32[128]\", p_unet_convs_3_conv3_conv_weight: \"f32[128, 64, 1, 1]\", p_unet_convs_3_conv3_conv_bias: \"f32[128]\", p_unet_convs_4_norm1_weight: \"f32[128]\", p_unet_convs_4_norm1_bias: \"f32[128]\", p_unet_convs_4_conv1_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_convs_4_conv1_conv_bias: \"f32[128]\", p_unet_convs_4_norm2_weight: \"f32[128]\", p_unet_convs_4_norm2_bias: \"f32[128]\", p_unet_convs_4_conv2_conv_weight: \"f32[256, 128, 3, 3]\", p_unet_convs_4_conv2_conv_bias: \"f32[256]\", p_unet_convs_4_conv3_conv_weight: \"f32[256, 128, 1, 1]\", p_unet_convs_4_conv3_conv_bias: \"f32[256]\", p_unet_convs_res_0_layers_0_norm1_weight: \"f32[16]\", p_unet_convs_res_0_layers_0_norm1_bias: \"f32[16]\", p_unet_convs_res_0_layers_0_conv1_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_convs_res_0_layers_0_conv1_conv_bias: \"f32[16]\", p_unet_convs_res_0_layers_0_norm2_weight: \"f32[16]\", p_unet_convs_res_0_layers_0_norm2_bias: \"f32[16]\", p_unet_convs_res_0_layers_0_conv2_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_convs_res_0_layers_0_conv2_conv_bias: \"f32[16]\", p_unet_convs_res_1_layers_0_norm1_weight: \"f32[32]\", p_unet_convs_res_1_layers_0_norm1_bias: \"f32[32]\", p_unet_convs_res_1_layers_0_conv1_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_convs_res_1_layers_0_conv1_conv_bias: \"f32[32]\", p_unet_convs_res_1_layers_0_norm2_weight: \"f32[32]\", p_unet_convs_res_1_layers_0_norm2_bias: \"f32[32]\", p_unet_convs_res_1_layers_0_conv2_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_convs_res_1_layers_0_conv2_conv_bias: \"f32[32]\", p_unet_convs_res_2_layers_0_norm1_weight: \"f32[64]\", p_unet_convs_res_2_layers_0_norm1_bias: \"f32[64]\", p_unet_convs_res_2_layers_0_conv1_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_convs_res_2_layers_0_conv1_conv_bias: \"f32[64]\", p_unet_convs_res_2_layers_0_norm2_weight: \"f32[64]\", p_unet_convs_res_2_layers_0_norm2_bias: \"f32[64]\", p_unet_convs_res_2_layers_0_conv2_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_convs_res_2_layers_0_conv2_conv_bias: \"f32[64]\", p_unet_convs_res_3_layers_0_norm1_weight: \"f32[128]\", p_unet_convs_res_3_layers_0_norm1_bias: \"f32[128]\", p_unet_convs_res_3_layers_0_conv1_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_convs_res_3_layers_0_conv1_conv_bias: \"f32[128]\", p_unet_convs_res_3_layers_0_norm2_weight: \"f32[128]\", p_unet_convs_res_3_layers_0_norm2_bias: \"f32[128]\", p_unet_convs_res_3_layers_0_conv2_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_convs_res_3_layers_0_conv2_conv_bias: \"f32[128]\", p_unet_convs_res_4_layers_0_norm1_weight: \"f32[256]\", p_unet_convs_res_4_layers_0_norm1_bias: \"f32[256]\", p_unet_convs_res_4_layers_0_conv1_conv_weight: \"f32[256, 256, 3, 3]\", p_unet_convs_res_4_layers_0_conv1_conv_bias: \"f32[256]\", p_unet_convs_res_4_layers_0_norm2_weight: \"f32[256]\", p_unet_convs_res_4_layers_0_norm2_bias: \"f32[256]\", p_unet_convs_res_4_layers_0_conv2_conv_weight: \"f32[256, 256, 3, 3]\", p_unet_convs_res_4_layers_0_conv2_conv_bias: \"f32[256]\", p_unet_convts_0_norm1_weight: \"f32[256]\", p_unet_convts_0_norm1_bias: \"f32[256]\", p_unet_convts_0_conv1_conv_weight: \"f32[256, 256, 3, 3]\", p_unet_convts_0_conv1_conv_bias: \"f32[256]\", p_unet_convts_0_norm2_weight: \"f32[256]\", p_unet_convts_0_norm2_bias: \"f32[256]\", p_unet_convts_0_conv2_conv_weight: \"f32[128, 256, 3, 3]\", p_unet_convts_0_conv2_conv_bias: \"f32[128]\", p_unet_convts_0_conv3_conv_weight: \"f32[128, 256, 1, 1]\", p_unet_convts_0_conv3_conv_bias: \"f32[128]\", p_unet_convts_1_norm1_weight: \"f32[128]\", p_unet_convts_1_norm1_bias: \"f32[128]\", p_unet_convts_1_conv1_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_convts_1_conv1_conv_bias: \"f32[128]\", p_unet_convts_1_norm2_weight: \"f32[128]\", p_unet_convts_1_norm2_bias: \"f32[128]\", p_unet_convts_1_conv2_conv_weight: \"f32[64, 128, 3, 3]\", p_unet_convts_1_conv2_conv_bias: \"f32[64]\", p_unet_convts_1_conv3_conv_weight: \"f32[64, 128, 1, 1]\", p_unet_convts_1_conv3_conv_bias: \"f32[64]\", p_unet_convts_2_norm1_weight: \"f32[64]\", p_unet_convts_2_norm1_bias: \"f32[64]\", p_unet_convts_2_conv1_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_convts_2_conv1_conv_bias: \"f32[64]\", p_unet_convts_2_norm2_weight: \"f32[64]\", p_unet_convts_2_norm2_bias: \"f32[64]\", p_unet_convts_2_conv2_conv_weight: \"f32[32, 64, 3, 3]\", p_unet_convts_2_conv2_conv_bias: \"f32[32]\", p_unet_convts_2_conv3_conv_weight: \"f32[32, 64, 1, 1]\", p_unet_convts_2_conv3_conv_bias: \"f32[32]\", p_unet_convts_3_norm1_weight: \"f32[32]\", p_unet_convts_3_norm1_bias: \"f32[32]\", p_unet_convts_3_conv1_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_convts_3_conv1_conv_bias: \"f32[32]\", p_unet_convts_3_norm2_weight: \"f32[32]\", p_unet_convts_3_norm2_bias: \"f32[32]\", p_unet_convts_3_conv2_conv_weight: \"f32[16, 32, 3, 3]\", p_unet_convts_3_conv2_conv_bias: \"f32[16]\", p_unet_convts_3_conv3_conv_weight: \"f32[16, 32, 1, 1]\", p_unet_convts_3_conv3_conv_bias: \"f32[16]\", p_unet_convts_res_0_layers_0_norm1_weight: \"f32[128]\", p_unet_convts_res_0_layers_0_norm1_bias: \"f32[128]\", p_unet_convts_res_0_layers_0_conv1_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_convts_res_0_layers_0_conv1_conv_bias: \"f32[128]\", p_unet_convts_res_0_layers_0_norm2_weight: \"f32[128]\", p_unet_convts_res_0_layers_0_norm2_bias: \"f32[128]\", p_unet_convts_res_0_layers_0_conv2_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_convts_res_0_layers_0_conv2_conv_bias: \"f32[128]\", p_unet_convts_res_1_layers_0_norm1_weight: \"f32[64]\", p_unet_convts_res_1_layers_0_norm1_bias: \"f32[64]\", p_unet_convts_res_1_layers_0_conv1_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_convts_res_1_layers_0_conv1_conv_bias: \"f32[64]\", p_unet_convts_res_1_layers_0_norm2_weight: \"f32[64]\", p_unet_convts_res_1_layers_0_norm2_bias: \"f32[64]\", p_unet_convts_res_1_layers_0_conv2_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_convts_res_1_layers_0_conv2_conv_bias: \"f32[64]\", p_unet_convts_res_2_layers_0_norm1_weight: \"f32[32]\", p_unet_convts_res_2_layers_0_norm1_bias: \"f32[32]\", p_unet_convts_res_2_layers_0_conv1_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_convts_res_2_layers_0_conv1_conv_bias: \"f32[32]\", p_unet_convts_res_2_layers_0_norm2_weight: \"f32[32]\", p_unet_convts_res_2_layers_0_norm2_bias: \"f32[32]\", p_unet_convts_res_2_layers_0_conv2_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_convts_res_2_layers_0_conv2_conv_bias: \"f32[32]\", p_unet_convts_res_3_layers_0_norm1_weight: \"f32[16]\", p_unet_convts_res_3_layers_0_norm1_bias: \"f32[16]\", p_unet_convts_res_3_layers_0_conv1_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_convts_res_3_layers_0_conv1_conv_bias: \"f32[16]\", p_unet_convts_res_3_layers_0_norm2_weight: \"f32[16]\", p_unet_convts_res_3_layers_0_norm2_bias: \"f32[16]\", p_unet_convts_res_3_layers_0_conv2_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_convts_res_3_layers_0_conv2_conv_bias: \"f32[16]\", p_unet_links_0_layers_0_norm1_weight: \"f32[128]\", p_unet_links_0_layers_0_norm1_bias: \"f32[128]\", p_unet_links_0_layers_0_conv1_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_links_0_layers_0_conv1_conv_bias: \"f32[128]\", p_unet_links_0_layers_0_norm2_weight: \"f32[128]\", p_unet_links_0_layers_0_norm2_bias: \"f32[128]\", p_unet_links_0_layers_0_conv2_conv_weight: \"f32[128, 128, 3, 3]\", p_unet_links_0_layers_0_conv2_conv_bias: \"f32[128]\", p_unet_links_1_layers_0_norm1_weight: \"f32[64]\", p_unet_links_1_layers_0_norm1_bias: \"f32[64]\", p_unet_links_1_layers_0_conv1_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_links_1_layers_0_conv1_conv_bias: \"f32[64]\", p_unet_links_1_layers_0_norm2_weight: \"f32[64]\", p_unet_links_1_layers_0_norm2_bias: \"f32[64]\", p_unet_links_1_layers_0_conv2_conv_weight: \"f32[64, 64, 3, 3]\", p_unet_links_1_layers_0_conv2_conv_bias: \"f32[64]\", p_unet_links_2_layers_0_norm1_weight: \"f32[32]\", p_unet_links_2_layers_0_norm1_bias: \"f32[32]\", p_unet_links_2_layers_0_conv1_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_links_2_layers_0_conv1_conv_bias: \"f32[32]\", p_unet_links_2_layers_0_norm2_weight: \"f32[32]\", p_unet_links_2_layers_0_norm2_bias: \"f32[32]\", p_unet_links_2_layers_0_conv2_conv_weight: \"f32[32, 32, 3, 3]\", p_unet_links_2_layers_0_conv2_conv_bias: \"f32[32]\", p_unet_links_3_layers_0_norm1_weight: \"f32[16]\", p_unet_links_3_layers_0_norm1_bias: \"f32[16]\", p_unet_links_3_layers_0_conv1_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_links_3_layers_0_conv1_conv_bias: \"f32[16]\", p_unet_links_3_layers_0_norm2_weight: \"f32[16]\", p_unet_links_3_layers_0_norm2_bias: \"f32[16]\", p_unet_links_3_layers_0_conv2_conv_weight: \"f32[16, 16, 3, 3]\", p_unet_links_3_layers_0_conv2_conv_bias: \"f32[16]\", p_convt_o1_weight: \"f32[16, 3, 3, 3]\", p_convt_o1_bias: \"f32[3]\", p_convt_o2_weight: \"f32[16, 1, 3, 3]\", p_convt_o2_bias: \"f32[1]\", b_unet_convs_0_norm1_running_mean: \"f32[1]\", b_unet_convs_0_norm1_running_var: \"f32[1]\", b_unet_convs_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_0_norm2_running_mean: \"f32[1]\", b_unet_convs_0_norm2_running_var: \"f32[1]\", b_unet_convs_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_1_norm1_running_mean: \"f32[16]\", b_unet_convs_1_norm1_running_var: \"f32[16]\", b_unet_convs_1_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_1_norm2_running_mean: \"f32[16]\", b_unet_convs_1_norm2_running_var: \"f32[16]\", b_unet_convs_1_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_2_norm1_running_mean: \"f32[32]\", b_unet_convs_2_norm1_running_var: \"f32[32]\", b_unet_convs_2_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_2_norm2_running_mean: \"f32[32]\", b_unet_convs_2_norm2_running_var: \"f32[32]\", b_unet_convs_2_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_3_norm1_running_mean: \"f32[64]\", b_unet_convs_3_norm1_running_var: \"f32[64]\", b_unet_convs_3_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_3_norm2_running_mean: \"f32[64]\", b_unet_convs_3_norm2_running_var: \"f32[64]\", b_unet_convs_3_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_4_norm1_running_mean: \"f32[128]\", b_unet_convs_4_norm1_running_var: \"f32[128]\", b_unet_convs_4_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_4_norm2_running_mean: \"f32[128]\", b_unet_convs_4_norm2_running_var: \"f32[128]\", b_unet_convs_4_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_res_0_layers_0_norm1_running_mean: \"f32[16]\", b_unet_convs_res_0_layers_0_norm1_running_var: \"f32[16]\", b_unet_convs_res_0_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_res_0_layers_0_norm2_running_mean: \"f32[16]\", b_unet_convs_res_0_layers_0_norm2_running_var: \"f32[16]\", b_unet_convs_res_0_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_res_1_layers_0_norm1_running_mean: \"f32[32]\", b_unet_convs_res_1_layers_0_norm1_running_var: \"f32[32]\", b_unet_convs_res_1_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_res_1_layers_0_norm2_running_mean: \"f32[32]\", b_unet_convs_res_1_layers_0_norm2_running_var: \"f32[32]\", b_unet_convs_res_1_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_res_2_layers_0_norm1_running_mean: \"f32[64]\", b_unet_convs_res_2_layers_0_norm1_running_var: \"f32[64]\", b_unet_convs_res_2_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_res_2_layers_0_norm2_running_mean: \"f32[64]\", b_unet_convs_res_2_layers_0_norm2_running_var: \"f32[64]\", b_unet_convs_res_2_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_res_3_layers_0_norm1_running_mean: \"f32[128]\", b_unet_convs_res_3_layers_0_norm1_running_var: \"f32[128]\", b_unet_convs_res_3_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_res_3_layers_0_norm2_running_mean: \"f32[128]\", b_unet_convs_res_3_layers_0_norm2_running_var: \"f32[128]\", b_unet_convs_res_3_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convs_res_4_layers_0_norm1_running_mean: \"f32[256]\", b_unet_convs_res_4_layers_0_norm1_running_var: \"f32[256]\", b_unet_convs_res_4_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convs_res_4_layers_0_norm2_running_mean: \"f32[256]\", b_unet_convs_res_4_layers_0_norm2_running_var: \"f32[256]\", b_unet_convs_res_4_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_0_norm1_running_mean: \"f32[256]\", b_unet_convts_0_norm1_running_var: \"f32[256]\", b_unet_convts_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_0_norm2_running_mean: \"f32[256]\", b_unet_convts_0_norm2_running_var: \"f32[256]\", b_unet_convts_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_1_norm1_running_mean: \"f32[128]\", b_unet_convts_1_norm1_running_var: \"f32[128]\", b_unet_convts_1_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_1_norm2_running_mean: \"f32[128]\", b_unet_convts_1_norm2_running_var: \"f32[128]\", b_unet_convts_1_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_2_norm1_running_mean: \"f32[64]\", b_unet_convts_2_norm1_running_var: \"f32[64]\", b_unet_convts_2_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_2_norm2_running_mean: \"f32[64]\", b_unet_convts_2_norm2_running_var: \"f32[64]\", b_unet_convts_2_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_3_norm1_running_mean: \"f32[32]\", b_unet_convts_3_norm1_running_var: \"f32[32]\", b_unet_convts_3_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_3_norm2_running_mean: \"f32[32]\", b_unet_convts_3_norm2_running_var: \"f32[32]\", b_unet_convts_3_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_res_0_layers_0_norm1_running_mean: \"f32[128]\", b_unet_convts_res_0_layers_0_norm1_running_var: \"f32[128]\", b_unet_convts_res_0_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_res_0_layers_0_norm2_running_mean: \"f32[128]\", b_unet_convts_res_0_layers_0_norm2_running_var: \"f32[128]\", b_unet_convts_res_0_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_res_1_layers_0_norm1_running_mean: \"f32[64]\", b_unet_convts_res_1_layers_0_norm1_running_var: \"f32[64]\", b_unet_convts_res_1_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_res_1_layers_0_norm2_running_mean: \"f32[64]\", b_unet_convts_res_1_layers_0_norm2_running_var: \"f32[64]\", b_unet_convts_res_1_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_res_2_layers_0_norm1_running_mean: \"f32[32]\", b_unet_convts_res_2_layers_0_norm1_running_var: \"f32[32]\", b_unet_convts_res_2_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_res_2_layers_0_norm2_running_mean: \"f32[32]\", b_unet_convts_res_2_layers_0_norm2_running_var: \"f32[32]\", b_unet_convts_res_2_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_convts_res_3_layers_0_norm1_running_mean: \"f32[16]\", b_unet_convts_res_3_layers_0_norm1_running_var: \"f32[16]\", b_unet_convts_res_3_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_convts_res_3_layers_0_norm2_running_mean: \"f32[16]\", b_unet_convts_res_3_layers_0_norm2_running_var: \"f32[16]\", b_unet_convts_res_3_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_links_0_layers_0_norm1_running_mean: \"f32[128]\", b_unet_links_0_layers_0_norm1_running_var: \"f32[128]\", b_unet_links_0_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_links_0_layers_0_norm2_running_mean: \"f32[128]\", b_unet_links_0_layers_0_norm2_running_var: \"f32[128]\", b_unet_links_0_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_links_1_layers_0_norm1_running_mean: \"f32[64]\", b_unet_links_1_layers_0_norm1_running_var: \"f32[64]\", b_unet_links_1_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_links_1_layers_0_norm2_running_mean: \"f32[64]\", b_unet_links_1_layers_0_norm2_running_var: \"f32[64]\", b_unet_links_1_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_links_2_layers_0_norm1_running_mean: \"f32[32]\", b_unet_links_2_layers_0_norm1_running_var: \"f32[32]\", b_unet_links_2_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_links_2_layers_0_norm2_running_mean: \"f32[32]\", b_unet_links_2_layers_0_norm2_running_var: \"f32[32]\", b_unet_links_2_layers_0_norm2_num_batches_tracked: \"i64[]\", b_unet_links_3_layers_0_norm1_running_mean: \"f32[16]\", b_unet_links_3_layers_0_norm1_running_var: \"f32[16]\", b_unet_links_3_layers_0_norm1_num_batches_tracked: \"i64[]\", b_unet_links_3_layers_0_norm2_running_mean: \"f32[16]\", b_unet_links_3_layers_0_norm2_running_var: \"f32[16]\", b_unet_links_3_layers_0_norm2_num_batches_tracked: \"i64[]\", x: \"f32[1, 1, 1984, 1472]\"):\n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:181 in forward, code: x -=  F.avg_pool2d(x, 101, stride=1, padding=50)\n",
       "                    avg_pool2d: \"f32[1, 1, 1984, 1472]\" = torch.ops.aten.avg_pool2d.default(x, [101, 101], [1, 1], [50, 50])\n",
       "                    sub: \"f32[1, 1, 1984, 1472]\" = torch.ops.aten.sub.Tensor(x, avg_pool2d);  x = avg_pool2d = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(sub, p_unet_convs_0_norm1_weight, p_unet_convs_0_norm1_bias, b_unet_convs_0_norm1_running_mean, b_unet_convs_0_norm1_running_var, 0.01, 1e-05);  p_unet_convs_0_norm1_weight = p_unet_convs_0_norm1_bias = b_unet_convs_0_norm1_running_mean = b_unet_convs_0_norm1_running_var = None\n",
       "                    getitem: \"f32[1, 1, 1984, 1472]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[1, 1, 1984, 1472]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[1, 1, 1984, 1472]\" = torch.ops.aten.conv2d.default(relu, p_unet_convs_0_conv1_conv_weight, p_unet_convs_0_conv1_conv_bias, [1, 1], [1, 1]);  relu = p_unet_convs_0_conv1_conv_weight = p_unet_convs_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d: \"f32[1, 1, 992, 736]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d, None, False, [0.5, 0.5]);  conv2d = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_1: \"f32[1, 1, 992, 736]\" = torch.ops.aten.upsample_bilinear2d.vec(sub, None, False, [0.5, 0.5])\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d, p_unet_convs_0_norm2_weight, p_unet_convs_0_norm2_bias, b_unet_convs_0_norm2_running_mean, b_unet_convs_0_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d = p_unet_convs_0_norm2_weight = p_unet_convs_0_norm2_bias = b_unet_convs_0_norm2_running_mean = b_unet_convs_0_norm2_running_var = None\n",
       "                    getitem_3: \"f32[1, 1, 992, 736]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[1, 1, 992, 736]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_1, p_unet_convs_0_conv2_conv_weight, p_unet_convs_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_1 = p_unet_convs_0_conv2_conv_weight = p_unet_convs_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_1, p_unet_convs_0_conv3_conv_weight, p_unet_convs_0_conv3_conv_bias);  upsample_bilinear2d_1 = p_unet_convs_0_conv3_conv_weight = p_unet_convs_0_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add: \"f32[1, 16, 992, 736]\" = torch.ops.aten.add.Tensor(conv2d_2, conv2d_1);  conv2d_2 = conv2d_1 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(add, p_unet_convs_res_0_layers_0_norm1_weight, p_unet_convs_res_0_layers_0_norm1_bias, b_unet_convs_res_0_layers_0_norm1_running_mean, b_unet_convs_res_0_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convs_res_0_layers_0_norm1_weight = p_unet_convs_res_0_layers_0_norm1_bias = b_unet_convs_res_0_layers_0_norm1_running_mean = b_unet_convs_res_0_layers_0_norm1_running_var = None\n",
       "                    getitem_6: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_2: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_6);  getitem_6 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_2, p_unet_convs_res_0_layers_0_conv1_conv_weight, p_unet_convs_res_0_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_2 = p_unet_convs_res_0_layers_0_conv1_conv_weight = p_unet_convs_res_0_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_unet_convs_res_0_layers_0_norm2_weight, p_unet_convs_res_0_layers_0_norm2_bias, b_unet_convs_res_0_layers_0_norm2_running_mean, b_unet_convs_res_0_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_3 = p_unet_convs_res_0_layers_0_norm2_weight = p_unet_convs_res_0_layers_0_norm2_bias = b_unet_convs_res_0_layers_0_norm2_running_mean = b_unet_convs_res_0_layers_0_norm2_running_var = None\n",
       "                    getitem_9: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_3: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_3, p_unet_convs_res_0_layers_0_conv2_conv_weight, p_unet_convs_res_0_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_3 = p_unet_convs_res_0_layers_0_conv2_conv_weight = p_unet_convs_res_0_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_1: \"f32[1, 16, 992, 736]\" = torch.ops.aten.add.Tensor(add, conv2d_4);  add = conv2d_4 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_1, p_unet_convs_1_norm1_weight, p_unet_convs_1_norm1_bias, b_unet_convs_1_norm1_running_mean, b_unet_convs_1_norm1_running_var, 0.01, 1e-05);  p_unet_convs_1_norm1_weight = p_unet_convs_1_norm1_bias = b_unet_convs_1_norm1_running_mean = b_unet_convs_1_norm1_running_var = None\n",
       "                    getitem_12: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_4: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_12);  getitem_12 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_4, p_unet_convs_1_conv1_conv_weight, p_unet_convs_1_conv1_conv_bias, [1, 1], [1, 1]);  relu_4 = p_unet_convs_1_conv1_conv_weight = p_unet_convs_1_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_2: \"f32[1, 16, 496, 368]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_5, None, False, [0.5, 0.5]);  conv2d_5 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_3: \"f32[1, 16, 496, 368]\" = torch.ops.aten.upsample_bilinear2d.vec(add_1, None, False, [0.5, 0.5])\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_2, p_unet_convs_1_norm2_weight, p_unet_convs_1_norm2_bias, b_unet_convs_1_norm2_running_mean, b_unet_convs_1_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_2 = p_unet_convs_1_norm2_weight = p_unet_convs_1_norm2_bias = b_unet_convs_1_norm2_running_mean = b_unet_convs_1_norm2_running_var = None\n",
       "                    getitem_15: \"f32[1, 16, 496, 368]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_5: \"f32[1, 16, 496, 368]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_5, p_unet_convs_1_conv2_conv_weight, p_unet_convs_1_conv2_conv_bias, [1, 1], [1, 1]);  relu_5 = p_unet_convs_1_conv2_conv_weight = p_unet_convs_1_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_3, p_unet_convs_1_conv3_conv_weight, p_unet_convs_1_conv3_conv_bias);  upsample_bilinear2d_3 = p_unet_convs_1_conv3_conv_weight = p_unet_convs_1_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_2: \"f32[1, 32, 496, 368]\" = torch.ops.aten.add.Tensor(conv2d_7, conv2d_6);  conv2d_7 = conv2d_6 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_2, p_unet_convs_res_1_layers_0_norm1_weight, p_unet_convs_res_1_layers_0_norm1_bias, b_unet_convs_res_1_layers_0_norm1_running_mean, b_unet_convs_res_1_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convs_res_1_layers_0_norm1_weight = p_unet_convs_res_1_layers_0_norm1_bias = b_unet_convs_res_1_layers_0_norm1_running_mean = b_unet_convs_res_1_layers_0_norm1_running_var = None\n",
       "                    getitem_18: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_6: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_18);  getitem_18 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_6, p_unet_convs_res_1_layers_0_conv1_conv_weight, p_unet_convs_res_1_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_6 = p_unet_convs_res_1_layers_0_conv1_conv_weight = p_unet_convs_res_1_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_unet_convs_res_1_layers_0_norm2_weight, p_unet_convs_res_1_layers_0_norm2_bias, b_unet_convs_res_1_layers_0_norm2_running_mean, b_unet_convs_res_1_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_8 = p_unet_convs_res_1_layers_0_norm2_weight = p_unet_convs_res_1_layers_0_norm2_bias = b_unet_convs_res_1_layers_0_norm2_running_mean = b_unet_convs_res_1_layers_0_norm2_running_var = None\n",
       "                    getitem_21: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_7: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_21);  getitem_21 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_7, p_unet_convs_res_1_layers_0_conv2_conv_weight, p_unet_convs_res_1_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_7 = p_unet_convs_res_1_layers_0_conv2_conv_weight = p_unet_convs_res_1_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_3: \"f32[1, 32, 496, 368]\" = torch.ops.aten.add.Tensor(add_2, conv2d_9);  add_2 = conv2d_9 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_3, p_unet_convs_2_norm1_weight, p_unet_convs_2_norm1_bias, b_unet_convs_2_norm1_running_mean, b_unet_convs_2_norm1_running_var, 0.01, 1e-05);  p_unet_convs_2_norm1_weight = p_unet_convs_2_norm1_bias = b_unet_convs_2_norm1_running_mean = b_unet_convs_2_norm1_running_var = None\n",
       "                    getitem_24: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_8: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_8, p_unet_convs_2_conv1_conv_weight, p_unet_convs_2_conv1_conv_bias, [1, 1], [1, 1]);  relu_8 = p_unet_convs_2_conv1_conv_weight = p_unet_convs_2_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_4: \"f32[1, 32, 248, 184]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_10, None, False, [0.5, 0.5]);  conv2d_10 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_5: \"f32[1, 32, 248, 184]\" = torch.ops.aten.upsample_bilinear2d.vec(add_3, None, False, [0.5, 0.5])\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_4, p_unet_convs_2_norm2_weight, p_unet_convs_2_norm2_bias, b_unet_convs_2_norm2_running_mean, b_unet_convs_2_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_4 = p_unet_convs_2_norm2_weight = p_unet_convs_2_norm2_bias = b_unet_convs_2_norm2_running_mean = b_unet_convs_2_norm2_running_var = None\n",
       "                    getitem_27: \"f32[1, 32, 248, 184]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_9: \"f32[1, 32, 248, 184]\" = torch.ops.aten.relu.default(getitem_27);  getitem_27 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_9, p_unet_convs_2_conv2_conv_weight, p_unet_convs_2_conv2_conv_bias, [1, 1], [1, 1]);  relu_9 = p_unet_convs_2_conv2_conv_weight = p_unet_convs_2_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_5, p_unet_convs_2_conv3_conv_weight, p_unet_convs_2_conv3_conv_bias);  upsample_bilinear2d_5 = p_unet_convs_2_conv3_conv_weight = p_unet_convs_2_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_4: \"f32[1, 64, 248, 184]\" = torch.ops.aten.add.Tensor(conv2d_12, conv2d_11);  conv2d_12 = conv2d_11 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_4, p_unet_convs_res_2_layers_0_norm1_weight, p_unet_convs_res_2_layers_0_norm1_bias, b_unet_convs_res_2_layers_0_norm1_running_mean, b_unet_convs_res_2_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convs_res_2_layers_0_norm1_weight = p_unet_convs_res_2_layers_0_norm1_bias = b_unet_convs_res_2_layers_0_norm1_running_mean = b_unet_convs_res_2_layers_0_norm1_running_var = None\n",
       "                    getitem_30: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_10: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_10, p_unet_convs_res_2_layers_0_conv1_conv_weight, p_unet_convs_res_2_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_10 = p_unet_convs_res_2_layers_0_conv1_conv_weight = p_unet_convs_res_2_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_unet_convs_res_2_layers_0_norm2_weight, p_unet_convs_res_2_layers_0_norm2_bias, b_unet_convs_res_2_layers_0_norm2_running_mean, b_unet_convs_res_2_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_13 = p_unet_convs_res_2_layers_0_norm2_weight = p_unet_convs_res_2_layers_0_norm2_bias = b_unet_convs_res_2_layers_0_norm2_running_mean = b_unet_convs_res_2_layers_0_norm2_running_var = None\n",
       "                    getitem_33: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_11: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_33);  getitem_33 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_11, p_unet_convs_res_2_layers_0_conv2_conv_weight, p_unet_convs_res_2_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_11 = p_unet_convs_res_2_layers_0_conv2_conv_weight = p_unet_convs_res_2_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_5: \"f32[1, 64, 248, 184]\" = torch.ops.aten.add.Tensor(add_4, conv2d_14);  add_4 = conv2d_14 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_5, p_unet_convs_3_norm1_weight, p_unet_convs_3_norm1_bias, b_unet_convs_3_norm1_running_mean, b_unet_convs_3_norm1_running_var, 0.01, 1e-05);  p_unet_convs_3_norm1_weight = p_unet_convs_3_norm1_bias = b_unet_convs_3_norm1_running_mean = b_unet_convs_3_norm1_running_var = None\n",
       "                    getitem_36: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_12: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_36);  getitem_36 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_15: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_12, p_unet_convs_3_conv1_conv_weight, p_unet_convs_3_conv1_conv_bias, [1, 1], [1, 1]);  relu_12 = p_unet_convs_3_conv1_conv_weight = p_unet_convs_3_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_6: \"f32[1, 64, 124, 92]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_15, None, False, [0.5, 0.5]);  conv2d_15 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_7: \"f32[1, 64, 124, 92]\" = torch.ops.aten.upsample_bilinear2d.vec(add_5, None, False, [0.5, 0.5])\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_6, p_unet_convs_3_norm2_weight, p_unet_convs_3_norm2_bias, b_unet_convs_3_norm2_running_mean, b_unet_convs_3_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_6 = p_unet_convs_3_norm2_weight = p_unet_convs_3_norm2_bias = b_unet_convs_3_norm2_running_mean = b_unet_convs_3_norm2_running_var = None\n",
       "                    getitem_39: \"f32[1, 64, 124, 92]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_13: \"f32[1, 64, 124, 92]\" = torch.ops.aten.relu.default(getitem_39);  getitem_39 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_16: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_13, p_unet_convs_3_conv2_conv_weight, p_unet_convs_3_conv2_conv_bias, [1, 1], [1, 1]);  relu_13 = p_unet_convs_3_conv2_conv_weight = p_unet_convs_3_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_17: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_7, p_unet_convs_3_conv3_conv_weight, p_unet_convs_3_conv3_conv_bias);  upsample_bilinear2d_7 = p_unet_convs_3_conv3_conv_weight = p_unet_convs_3_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_6: \"f32[1, 128, 124, 92]\" = torch.ops.aten.add.Tensor(conv2d_17, conv2d_16);  conv2d_17 = conv2d_16 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_6, p_unet_convs_res_3_layers_0_norm1_weight, p_unet_convs_res_3_layers_0_norm1_bias, b_unet_convs_res_3_layers_0_norm1_running_mean, b_unet_convs_res_3_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convs_res_3_layers_0_norm1_weight = p_unet_convs_res_3_layers_0_norm1_bias = b_unet_convs_res_3_layers_0_norm1_running_mean = b_unet_convs_res_3_layers_0_norm1_running_var = None\n",
       "                    getitem_42: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_14: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_42);  getitem_42 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_18: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_14, p_unet_convs_res_3_layers_0_conv1_conv_weight, p_unet_convs_res_3_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_14 = p_unet_convs_res_3_layers_0_conv1_conv_weight = p_unet_convs_res_3_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_unet_convs_res_3_layers_0_norm2_weight, p_unet_convs_res_3_layers_0_norm2_bias, b_unet_convs_res_3_layers_0_norm2_running_mean, b_unet_convs_res_3_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_18 = p_unet_convs_res_3_layers_0_norm2_weight = p_unet_convs_res_3_layers_0_norm2_bias = b_unet_convs_res_3_layers_0_norm2_running_mean = b_unet_convs_res_3_layers_0_norm2_running_var = None\n",
       "                    getitem_45: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_15: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_19: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_15, p_unet_convs_res_3_layers_0_conv2_conv_weight, p_unet_convs_res_3_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_15 = p_unet_convs_res_3_layers_0_conv2_conv_weight = p_unet_convs_res_3_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_7: \"f32[1, 128, 124, 92]\" = torch.ops.aten.add.Tensor(add_6, conv2d_19);  add_6 = conv2d_19 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_7, p_unet_convs_4_norm1_weight, p_unet_convs_4_norm1_bias, b_unet_convs_4_norm1_running_mean, b_unet_convs_4_norm1_running_var, 0.01, 1e-05);  p_unet_convs_4_norm1_weight = p_unet_convs_4_norm1_bias = b_unet_convs_4_norm1_running_mean = b_unet_convs_4_norm1_running_var = None\n",
       "                    getitem_48: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_16: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_48);  getitem_48 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_20: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_16, p_unet_convs_4_conv1_conv_weight, p_unet_convs_4_conv1_conv_bias, [1, 1], [1, 1]);  relu_16 = p_unet_convs_4_conv1_conv_weight = p_unet_convs_4_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_8: \"f32[1, 128, 62, 46]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_20, None, False, [0.5, 0.5]);  conv2d_20 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_9: \"f32[1, 128, 62, 46]\" = torch.ops.aten.upsample_bilinear2d.vec(add_7, None, False, [0.5, 0.5])\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_8, p_unet_convs_4_norm2_weight, p_unet_convs_4_norm2_bias, b_unet_convs_4_norm2_running_mean, b_unet_convs_4_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_8 = p_unet_convs_4_norm2_weight = p_unet_convs_4_norm2_bias = b_unet_convs_4_norm2_running_mean = b_unet_convs_4_norm2_running_var = None\n",
       "                    getitem_51: \"f32[1, 128, 62, 46]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_17: \"f32[1, 128, 62, 46]\" = torch.ops.aten.relu.default(getitem_51);  getitem_51 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_21: \"f32[1, 256, 62, 46]\" = torch.ops.aten.conv2d.default(relu_17, p_unet_convs_4_conv2_conv_weight, p_unet_convs_4_conv2_conv_bias, [1, 1], [1, 1]);  relu_17 = p_unet_convs_4_conv2_conv_weight = p_unet_convs_4_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_22: \"f32[1, 256, 62, 46]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_9, p_unet_convs_4_conv3_conv_weight, p_unet_convs_4_conv3_conv_bias);  upsample_bilinear2d_9 = p_unet_convs_4_conv3_conv_weight = p_unet_convs_4_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_8: \"f32[1, 256, 62, 46]\" = torch.ops.aten.add.Tensor(conv2d_22, conv2d_21);  conv2d_22 = conv2d_21 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_8, p_unet_convs_res_4_layers_0_norm1_weight, p_unet_convs_res_4_layers_0_norm1_bias, b_unet_convs_res_4_layers_0_norm1_running_mean, b_unet_convs_res_4_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convs_res_4_layers_0_norm1_weight = p_unet_convs_res_4_layers_0_norm1_bias = b_unet_convs_res_4_layers_0_norm1_running_mean = b_unet_convs_res_4_layers_0_norm1_running_var = None\n",
       "                    getitem_54: \"f32[1, 256, 62, 46]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_18: \"f32[1, 256, 62, 46]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_23: \"f32[1, 256, 62, 46]\" = torch.ops.aten.conv2d.default(relu_18, p_unet_convs_res_4_layers_0_conv1_conv_weight, p_unet_convs_res_4_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_18 = p_unet_convs_res_4_layers_0_conv1_conv_weight = p_unet_convs_res_4_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_23, p_unet_convs_res_4_layers_0_norm2_weight, p_unet_convs_res_4_layers_0_norm2_bias, b_unet_convs_res_4_layers_0_norm2_running_mean, b_unet_convs_res_4_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_23 = p_unet_convs_res_4_layers_0_norm2_weight = p_unet_convs_res_4_layers_0_norm2_bias = b_unet_convs_res_4_layers_0_norm2_running_mean = b_unet_convs_res_4_layers_0_norm2_running_var = None\n",
       "                    getitem_57: \"f32[1, 256, 62, 46]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_19: \"f32[1, 256, 62, 46]\" = torch.ops.aten.relu.default(getitem_57);  getitem_57 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_24: \"f32[1, 256, 62, 46]\" = torch.ops.aten.conv2d.default(relu_19, p_unet_convs_res_4_layers_0_conv2_conv_weight, p_unet_convs_res_4_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_19 = p_unet_convs_res_4_layers_0_conv2_conv_weight = p_unet_convs_res_4_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_9: \"f32[1, 256, 62, 46]\" = torch.ops.aten.add.Tensor(add_8, conv2d_24);  add_8 = conv2d_24 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_9, p_unet_convts_0_norm1_weight, p_unet_convts_0_norm1_bias, b_unet_convts_0_norm1_running_mean, b_unet_convts_0_norm1_running_var, 0.01, 1e-05);  p_unet_convts_0_norm1_weight = p_unet_convts_0_norm1_bias = b_unet_convts_0_norm1_running_mean = b_unet_convts_0_norm1_running_var = None\n",
       "                    getitem_60: \"f32[1, 256, 62, 46]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_20: \"f32[1, 256, 62, 46]\" = torch.ops.aten.relu.default(getitem_60);  getitem_60 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_25: \"f32[1, 256, 62, 46]\" = torch.ops.aten.conv2d.default(relu_20, p_unet_convts_0_conv1_conv_weight, p_unet_convts_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_20 = p_unet_convts_0_conv1_conv_weight = p_unet_convts_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_10: \"f32[1, 256, 124, 92]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_25, None, False, [2.0, 2.0]);  conv2d_25 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_11: \"f32[1, 256, 124, 92]\" = torch.ops.aten.upsample_bilinear2d.vec(add_9, None, False, [2.0, 2.0]);  add_9 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_10, p_unet_convts_0_norm2_weight, p_unet_convts_0_norm2_bias, b_unet_convts_0_norm2_running_mean, b_unet_convts_0_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_10 = p_unet_convts_0_norm2_weight = p_unet_convts_0_norm2_bias = b_unet_convts_0_norm2_running_mean = b_unet_convts_0_norm2_running_var = None\n",
       "                    getitem_63: \"f32[1, 256, 124, 92]\" = _native_batch_norm_legit_no_training_21[0];  _native_batch_norm_legit_no_training_21 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_21: \"f32[1, 256, 124, 92]\" = torch.ops.aten.relu.default(getitem_63);  getitem_63 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_26: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_21, p_unet_convts_0_conv2_conv_weight, p_unet_convts_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_21 = p_unet_convts_0_conv2_conv_weight = p_unet_convts_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_27: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_11, p_unet_convts_0_conv3_conv_weight, p_unet_convts_0_conv3_conv_bias);  upsample_bilinear2d_11 = p_unet_convts_0_conv3_conv_weight = p_unet_convts_0_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_10: \"f32[1, 128, 124, 92]\" = torch.ops.aten.add.Tensor(conv2d_27, conv2d_26);  conv2d_27 = conv2d_26 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_10, p_unet_convts_res_0_layers_0_norm1_weight, p_unet_convts_res_0_layers_0_norm1_bias, b_unet_convts_res_0_layers_0_norm1_running_mean, b_unet_convts_res_0_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convts_res_0_layers_0_norm1_weight = p_unet_convts_res_0_layers_0_norm1_bias = b_unet_convts_res_0_layers_0_norm1_running_mean = b_unet_convts_res_0_layers_0_norm1_running_var = None\n",
       "                    getitem_66: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_22: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_66);  getitem_66 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_28: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_22, p_unet_convts_res_0_layers_0_conv1_conv_weight, p_unet_convts_res_0_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_22 = p_unet_convts_res_0_layers_0_conv1_conv_weight = p_unet_convts_res_0_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_28, p_unet_convts_res_0_layers_0_norm2_weight, p_unet_convts_res_0_layers_0_norm2_bias, b_unet_convts_res_0_layers_0_norm2_running_mean, b_unet_convts_res_0_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_28 = p_unet_convts_res_0_layers_0_norm2_weight = p_unet_convts_res_0_layers_0_norm2_bias = b_unet_convts_res_0_layers_0_norm2_running_mean = b_unet_convts_res_0_layers_0_norm2_running_var = None\n",
       "                    getitem_69: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_23[0];  _native_batch_norm_legit_no_training_23 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_23: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_69);  getitem_69 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_29: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_23, p_unet_convts_res_0_layers_0_conv2_conv_weight, p_unet_convts_res_0_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_23 = p_unet_convts_res_0_layers_0_conv2_conv_weight = p_unet_convts_res_0_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_11: \"f32[1, 128, 124, 92]\" = torch.ops.aten.add.Tensor(add_10, conv2d_29);  add_10 = conv2d_29 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_7, p_unet_links_0_layers_0_norm1_weight, p_unet_links_0_layers_0_norm1_bias, b_unet_links_0_layers_0_norm1_running_mean, b_unet_links_0_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_links_0_layers_0_norm1_weight = p_unet_links_0_layers_0_norm1_bias = b_unet_links_0_layers_0_norm1_running_mean = b_unet_links_0_layers_0_norm1_running_var = None\n",
       "                    getitem_72: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_24: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_72);  getitem_72 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_30: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_24, p_unet_links_0_layers_0_conv1_conv_weight, p_unet_links_0_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_24 = p_unet_links_0_layers_0_conv1_conv_weight = p_unet_links_0_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_30, p_unet_links_0_layers_0_norm2_weight, p_unet_links_0_layers_0_norm2_bias, b_unet_links_0_layers_0_norm2_running_mean, b_unet_links_0_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_30 = p_unet_links_0_layers_0_norm2_weight = p_unet_links_0_layers_0_norm2_bias = b_unet_links_0_layers_0_norm2_running_mean = b_unet_links_0_layers_0_norm2_running_var = None\n",
       "                    getitem_75: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_25[0];  _native_batch_norm_legit_no_training_25 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_25: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_75);  getitem_75 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_31: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_25, p_unet_links_0_layers_0_conv2_conv_weight, p_unet_links_0_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_25 = p_unet_links_0_layers_0_conv2_conv_weight = p_unet_links_0_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_12: \"f32[1, 128, 124, 92]\" = torch.ops.aten.add.Tensor(add_7, conv2d_31);  add_7 = conv2d_31 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:165 in forward, code: if(j-i>=0): x=x+link(y[j-i]) #Aplica el enlace a la primera seccion\n",
       "                    add_13: \"f32[1, 128, 124, 92]\" = torch.ops.aten.add.Tensor(add_11, add_12);  add_11 = add_12 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_13, p_unet_convts_1_norm1_weight, p_unet_convts_1_norm1_bias, b_unet_convts_1_norm1_running_mean, b_unet_convts_1_norm1_running_var, 0.01, 1e-05);  p_unet_convts_1_norm1_weight = p_unet_convts_1_norm1_bias = b_unet_convts_1_norm1_running_mean = b_unet_convts_1_norm1_running_var = None\n",
       "                    getitem_78: \"f32[1, 128, 124, 92]\" = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_26: \"f32[1, 128, 124, 92]\" = torch.ops.aten.relu.default(getitem_78);  getitem_78 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_32: \"f32[1, 128, 124, 92]\" = torch.ops.aten.conv2d.default(relu_26, p_unet_convts_1_conv1_conv_weight, p_unet_convts_1_conv1_conv_bias, [1, 1], [1, 1]);  relu_26 = p_unet_convts_1_conv1_conv_weight = p_unet_convts_1_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_12: \"f32[1, 128, 248, 184]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_32, None, False, [2.0, 2.0]);  conv2d_32 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_13: \"f32[1, 128, 248, 184]\" = torch.ops.aten.upsample_bilinear2d.vec(add_13, None, False, [2.0, 2.0]);  add_13 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_12, p_unet_convts_1_norm2_weight, p_unet_convts_1_norm2_bias, b_unet_convts_1_norm2_running_mean, b_unet_convts_1_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_12 = p_unet_convts_1_norm2_weight = p_unet_convts_1_norm2_bias = b_unet_convts_1_norm2_running_mean = b_unet_convts_1_norm2_running_var = None\n",
       "                    getitem_81: \"f32[1, 128, 248, 184]\" = _native_batch_norm_legit_no_training_27[0];  _native_batch_norm_legit_no_training_27 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_27: \"f32[1, 128, 248, 184]\" = torch.ops.aten.relu.default(getitem_81);  getitem_81 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_33: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_27, p_unet_convts_1_conv2_conv_weight, p_unet_convts_1_conv2_conv_bias, [1, 1], [1, 1]);  relu_27 = p_unet_convts_1_conv2_conv_weight = p_unet_convts_1_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_34: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_13, p_unet_convts_1_conv3_conv_weight, p_unet_convts_1_conv3_conv_bias);  upsample_bilinear2d_13 = p_unet_convts_1_conv3_conv_weight = p_unet_convts_1_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_14: \"f32[1, 64, 248, 184]\" = torch.ops.aten.add.Tensor(conv2d_34, conv2d_33);  conv2d_34 = conv2d_33 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_14, p_unet_convts_res_1_layers_0_norm1_weight, p_unet_convts_res_1_layers_0_norm1_bias, b_unet_convts_res_1_layers_0_norm1_running_mean, b_unet_convts_res_1_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convts_res_1_layers_0_norm1_weight = p_unet_convts_res_1_layers_0_norm1_bias = b_unet_convts_res_1_layers_0_norm1_running_mean = b_unet_convts_res_1_layers_0_norm1_running_var = None\n",
       "                    getitem_84: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_28: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_84);  getitem_84 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_35: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_28, p_unet_convts_res_1_layers_0_conv1_conv_weight, p_unet_convts_res_1_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_28 = p_unet_convts_res_1_layers_0_conv1_conv_weight = p_unet_convts_res_1_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_35, p_unet_convts_res_1_layers_0_norm2_weight, p_unet_convts_res_1_layers_0_norm2_bias, b_unet_convts_res_1_layers_0_norm2_running_mean, b_unet_convts_res_1_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_35 = p_unet_convts_res_1_layers_0_norm2_weight = p_unet_convts_res_1_layers_0_norm2_bias = b_unet_convts_res_1_layers_0_norm2_running_mean = b_unet_convts_res_1_layers_0_norm2_running_var = None\n",
       "                    getitem_87: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_29[0];  _native_batch_norm_legit_no_training_29 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_29: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_87);  getitem_87 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_36: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_29, p_unet_convts_res_1_layers_0_conv2_conv_weight, p_unet_convts_res_1_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_29 = p_unet_convts_res_1_layers_0_conv2_conv_weight = p_unet_convts_res_1_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_15: \"f32[1, 64, 248, 184]\" = torch.ops.aten.add.Tensor(add_14, conv2d_36);  add_14 = conv2d_36 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_5, p_unet_links_1_layers_0_norm1_weight, p_unet_links_1_layers_0_norm1_bias, b_unet_links_1_layers_0_norm1_running_mean, b_unet_links_1_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_links_1_layers_0_norm1_weight = p_unet_links_1_layers_0_norm1_bias = b_unet_links_1_layers_0_norm1_running_mean = b_unet_links_1_layers_0_norm1_running_var = None\n",
       "                    getitem_90: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_30: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_90);  getitem_90 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_37: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_30, p_unet_links_1_layers_0_conv1_conv_weight, p_unet_links_1_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_30 = p_unet_links_1_layers_0_conv1_conv_weight = p_unet_links_1_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_37, p_unet_links_1_layers_0_norm2_weight, p_unet_links_1_layers_0_norm2_bias, b_unet_links_1_layers_0_norm2_running_mean, b_unet_links_1_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_37 = p_unet_links_1_layers_0_norm2_weight = p_unet_links_1_layers_0_norm2_bias = b_unet_links_1_layers_0_norm2_running_mean = b_unet_links_1_layers_0_norm2_running_var = None\n",
       "                    getitem_93: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_31[0];  _native_batch_norm_legit_no_training_31 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_31: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_93);  getitem_93 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_38: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_31, p_unet_links_1_layers_0_conv2_conv_weight, p_unet_links_1_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_31 = p_unet_links_1_layers_0_conv2_conv_weight = p_unet_links_1_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_16: \"f32[1, 64, 248, 184]\" = torch.ops.aten.add.Tensor(add_5, conv2d_38);  add_5 = conv2d_38 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:165 in forward, code: if(j-i>=0): x=x+link(y[j-i]) #Aplica el enlace a la primera seccion\n",
       "                    add_17: \"f32[1, 64, 248, 184]\" = torch.ops.aten.add.Tensor(add_15, add_16);  add_15 = add_16 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_17, p_unet_convts_2_norm1_weight, p_unet_convts_2_norm1_bias, b_unet_convts_2_norm1_running_mean, b_unet_convts_2_norm1_running_var, 0.01, 1e-05);  p_unet_convts_2_norm1_weight = p_unet_convts_2_norm1_bias = b_unet_convts_2_norm1_running_mean = b_unet_convts_2_norm1_running_var = None\n",
       "                    getitem_96: \"f32[1, 64, 248, 184]\" = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_32: \"f32[1, 64, 248, 184]\" = torch.ops.aten.relu.default(getitem_96);  getitem_96 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_39: \"f32[1, 64, 248, 184]\" = torch.ops.aten.conv2d.default(relu_32, p_unet_convts_2_conv1_conv_weight, p_unet_convts_2_conv1_conv_bias, [1, 1], [1, 1]);  relu_32 = p_unet_convts_2_conv1_conv_weight = p_unet_convts_2_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_14: \"f32[1, 64, 496, 368]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_39, None, False, [2.0, 2.0]);  conv2d_39 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_15: \"f32[1, 64, 496, 368]\" = torch.ops.aten.upsample_bilinear2d.vec(add_17, None, False, [2.0, 2.0]);  add_17 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_14, p_unet_convts_2_norm2_weight, p_unet_convts_2_norm2_bias, b_unet_convts_2_norm2_running_mean, b_unet_convts_2_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_14 = p_unet_convts_2_norm2_weight = p_unet_convts_2_norm2_bias = b_unet_convts_2_norm2_running_mean = b_unet_convts_2_norm2_running_var = None\n",
       "                    getitem_99: \"f32[1, 64, 496, 368]\" = _native_batch_norm_legit_no_training_33[0];  _native_batch_norm_legit_no_training_33 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_33: \"f32[1, 64, 496, 368]\" = torch.ops.aten.relu.default(getitem_99);  getitem_99 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_40: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_33, p_unet_convts_2_conv2_conv_weight, p_unet_convts_2_conv2_conv_bias, [1, 1], [1, 1]);  relu_33 = p_unet_convts_2_conv2_conv_weight = p_unet_convts_2_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_41: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_15, p_unet_convts_2_conv3_conv_weight, p_unet_convts_2_conv3_conv_bias);  upsample_bilinear2d_15 = p_unet_convts_2_conv3_conv_weight = p_unet_convts_2_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_18: \"f32[1, 32, 496, 368]\" = torch.ops.aten.add.Tensor(conv2d_41, conv2d_40);  conv2d_41 = conv2d_40 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_18, p_unet_convts_res_2_layers_0_norm1_weight, p_unet_convts_res_2_layers_0_norm1_bias, b_unet_convts_res_2_layers_0_norm1_running_mean, b_unet_convts_res_2_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convts_res_2_layers_0_norm1_weight = p_unet_convts_res_2_layers_0_norm1_bias = b_unet_convts_res_2_layers_0_norm1_running_mean = b_unet_convts_res_2_layers_0_norm1_running_var = None\n",
       "                    getitem_102: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_34: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_102);  getitem_102 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_42: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_34, p_unet_convts_res_2_layers_0_conv1_conv_weight, p_unet_convts_res_2_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_34 = p_unet_convts_res_2_layers_0_conv1_conv_weight = p_unet_convts_res_2_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_42, p_unet_convts_res_2_layers_0_norm2_weight, p_unet_convts_res_2_layers_0_norm2_bias, b_unet_convts_res_2_layers_0_norm2_running_mean, b_unet_convts_res_2_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_42 = p_unet_convts_res_2_layers_0_norm2_weight = p_unet_convts_res_2_layers_0_norm2_bias = b_unet_convts_res_2_layers_0_norm2_running_mean = b_unet_convts_res_2_layers_0_norm2_running_var = None\n",
       "                    getitem_105: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_35[0];  _native_batch_norm_legit_no_training_35 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_35: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_105);  getitem_105 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_43: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_35, p_unet_convts_res_2_layers_0_conv2_conv_weight, p_unet_convts_res_2_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_35 = p_unet_convts_res_2_layers_0_conv2_conv_weight = p_unet_convts_res_2_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_19: \"f32[1, 32, 496, 368]\" = torch.ops.aten.add.Tensor(add_18, conv2d_43);  add_18 = conv2d_43 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_3, p_unet_links_2_layers_0_norm1_weight, p_unet_links_2_layers_0_norm1_bias, b_unet_links_2_layers_0_norm1_running_mean, b_unet_links_2_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_links_2_layers_0_norm1_weight = p_unet_links_2_layers_0_norm1_bias = b_unet_links_2_layers_0_norm1_running_mean = b_unet_links_2_layers_0_norm1_running_var = None\n",
       "                    getitem_108: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_36: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_108);  getitem_108 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_44: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_36, p_unet_links_2_layers_0_conv1_conv_weight, p_unet_links_2_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_36 = p_unet_links_2_layers_0_conv1_conv_weight = p_unet_links_2_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_44, p_unet_links_2_layers_0_norm2_weight, p_unet_links_2_layers_0_norm2_bias, b_unet_links_2_layers_0_norm2_running_mean, b_unet_links_2_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_44 = p_unet_links_2_layers_0_norm2_weight = p_unet_links_2_layers_0_norm2_bias = b_unet_links_2_layers_0_norm2_running_mean = b_unet_links_2_layers_0_norm2_running_var = None\n",
       "                    getitem_111: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_37[0];  _native_batch_norm_legit_no_training_37 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_37: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_111);  getitem_111 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_45: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_37, p_unet_links_2_layers_0_conv2_conv_weight, p_unet_links_2_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_37 = p_unet_links_2_layers_0_conv2_conv_weight = p_unet_links_2_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_20: \"f32[1, 32, 496, 368]\" = torch.ops.aten.add.Tensor(add_3, conv2d_45);  add_3 = conv2d_45 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:165 in forward, code: if(j-i>=0): x=x+link(y[j-i]) #Aplica el enlace a la primera seccion\n",
       "                    add_21: \"f32[1, 32, 496, 368]\" = torch.ops.aten.add.Tensor(add_19, add_20);  add_19 = add_20 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_21, p_unet_convts_3_norm1_weight, p_unet_convts_3_norm1_bias, b_unet_convts_3_norm1_running_mean, b_unet_convts_3_norm1_running_var, 0.01, 1e-05);  p_unet_convts_3_norm1_weight = p_unet_convts_3_norm1_bias = b_unet_convts_3_norm1_running_mean = b_unet_convts_3_norm1_running_var = None\n",
       "                    getitem_114: \"f32[1, 32, 496, 368]\" = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_38: \"f32[1, 32, 496, 368]\" = torch.ops.aten.relu.default(getitem_114);  getitem_114 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_46: \"f32[1, 32, 496, 368]\" = torch.ops.aten.conv2d.default(relu_38, p_unet_convts_3_conv1_conv_weight, p_unet_convts_3_conv1_conv_bias, [1, 1], [1, 1]);  relu_38 = p_unet_convts_3_conv1_conv_weight = p_unet_convts_3_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:88 in forward, code: x  = F.interpolate(x, scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_16: \"f32[1, 32, 992, 736]\" = torch.ops.aten.upsample_bilinear2d.vec(conv2d_46, None, False, [2.0, 2.0]);  conv2d_46 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:89 in forward, code: x0 = F.interpolate(x0,scale_factor=self.resample, mode='bilinear')\n",
       "                    upsample_bilinear2d_17: \"f32[1, 32, 992, 736]\" = torch.ops.aten.upsample_bilinear2d.vec(add_21, None, False, [2.0, 2.0]);  add_21 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(upsample_bilinear2d_16, p_unet_convts_3_norm2_weight, p_unet_convts_3_norm2_bias, b_unet_convts_3_norm2_running_mean, b_unet_convts_3_norm2_running_var, 0.01, 1e-05);  upsample_bilinear2d_16 = p_unet_convts_3_norm2_weight = p_unet_convts_3_norm2_bias = b_unet_convts_3_norm2_running_mean = b_unet_convts_3_norm2_running_var = None\n",
       "                    getitem_117: \"f32[1, 32, 992, 736]\" = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_39: \"f32[1, 32, 992, 736]\" = torch.ops.aten.relu.default(getitem_117);  getitem_117 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_47: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_39, p_unet_convts_3_conv2_conv_weight, p_unet_convts_3_conv2_conv_bias, [1, 1], [1, 1]);  relu_39 = p_unet_convts_3_conv2_conv_weight = p_unet_convts_3_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_48: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(upsample_bilinear2d_17, p_unet_convts_3_conv3_conv_weight, p_unet_convts_3_conv3_conv_bias);  upsample_bilinear2d_17 = p_unet_convts_3_conv3_conv_weight = p_unet_convts_3_conv3_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_22: \"f32[1, 16, 992, 736]\" = torch.ops.aten.add.Tensor(conv2d_48, conv2d_47);  conv2d_48 = conv2d_47 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_22, p_unet_convts_res_3_layers_0_norm1_weight, p_unet_convts_res_3_layers_0_norm1_bias, b_unet_convts_res_3_layers_0_norm1_running_mean, b_unet_convts_res_3_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_convts_res_3_layers_0_norm1_weight = p_unet_convts_res_3_layers_0_norm1_bias = b_unet_convts_res_3_layers_0_norm1_running_mean = b_unet_convts_res_3_layers_0_norm1_running_var = None\n",
       "                    getitem_120: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_40[0];  _native_batch_norm_legit_no_training_40 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_40: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_120);  getitem_120 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_49: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_40, p_unet_convts_res_3_layers_0_conv1_conv_weight, p_unet_convts_res_3_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_40 = p_unet_convts_res_3_layers_0_conv1_conv_weight = p_unet_convts_res_3_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_49, p_unet_convts_res_3_layers_0_norm2_weight, p_unet_convts_res_3_layers_0_norm2_bias, b_unet_convts_res_3_layers_0_norm2_running_mean, b_unet_convts_res_3_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_49 = p_unet_convts_res_3_layers_0_norm2_weight = p_unet_convts_res_3_layers_0_norm2_bias = b_unet_convts_res_3_layers_0_norm2_running_mean = b_unet_convts_res_3_layers_0_norm2_running_var = None\n",
       "                    getitem_123: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_41: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_123);  getitem_123 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_50: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_41, p_unet_convts_res_3_layers_0_conv2_conv_weight, p_unet_convts_res_3_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_41 = p_unet_convts_res_3_layers_0_conv2_conv_weight = p_unet_convts_res_3_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_23: \"f32[1, 16, 992, 736]\" = torch.ops.aten.add.Tensor(add_22, conv2d_50);  add_22 = conv2d_50 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(add_1, p_unet_links_3_layers_0_norm1_weight, p_unet_links_3_layers_0_norm1_bias, b_unet_links_3_layers_0_norm1_running_mean, b_unet_links_3_layers_0_norm1_running_var, 0.01, 1e-05);  p_unet_links_3_layers_0_norm1_weight = p_unet_links_3_layers_0_norm1_bias = b_unet_links_3_layers_0_norm1_running_mean = b_unet_links_3_layers_0_norm1_running_var = None\n",
       "                    getitem_126: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_42[0];  _native_batch_norm_legit_no_training_42 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_42: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_126);  getitem_126 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_51: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_42, p_unet_links_3_layers_0_conv1_conv_weight, p_unet_links_3_layers_0_conv1_conv_bias, [1, 1], [1, 1]);  relu_42 = p_unet_links_3_layers_0_conv1_conv_weight = p_unet_links_3_layers_0_conv1_conv_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_51, p_unet_links_3_layers_0_norm2_weight, p_unet_links_3_layers_0_norm2_bias, b_unet_links_3_layers_0_norm2_running_mean, b_unet_links_3_layers_0_norm2_running_var, 0.01, 1e-05);  conv2d_51 = p_unet_links_3_layers_0_norm2_weight = p_unet_links_3_layers_0_norm2_bias = b_unet_links_3_layers_0_norm2_running_mean = b_unet_links_3_layers_0_norm2_running_var = None\n",
       "                    getitem_129: \"f32[1, 16, 992, 736]\" = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/activation.py:133 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_43: \"f32[1, 16, 992, 736]\" = torch.ops.aten.relu.default(getitem_129);  getitem_129 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_52: \"f32[1, 16, 992, 736]\" = torch.ops.aten.conv2d.default(relu_43, p_unet_links_3_layers_0_conv2_conv_weight, p_unet_links_3_layers_0_conv2_conv_bias, [1, 1], [1, 1]);  relu_43 = p_unet_links_3_layers_0_conv2_conv_weight = p_unet_links_3_layers_0_conv2_conv_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:98 in forward, code: return x0 + x\n",
       "                    add_24: \"f32[1, 16, 992, 736]\" = torch.ops.aten.add.Tensor(add_1, conv2d_52);  add_1 = conv2d_52 = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:165 in forward, code: if(j-i>=0): x=x+link(y[j-i]) #Aplica el enlace a la primera seccion\n",
       "                    add_25: \"f32[1, 16, 992, 736]\" = torch.ops.aten.add.Tensor(add_23, add_24);  add_23 = add_24 = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:1162 in forward, code: return F.conv_transpose2d(\n",
       "                    convolution: \"f32[1, 3, 1984, 1472]\" = torch.ops.aten.convolution.default(add_25, p_convt_o1_weight, p_convt_o1_bias, [2, 2], [1, 1], [1, 1], True, [1, 1], 1);  p_convt_o1_weight = p_convt_o1_bias = None\n",
       "            \n",
       "                     # File: /home/yeriel/workspace/pretiles/env/lib/python3.10/site-packages/torch/nn/modules/conv.py:1162 in forward, code: return F.conv_transpose2d(\n",
       "                    convolution_1: \"f32[1, 1, 1984, 1472]\" = torch.ops.aten.convolution.default(add_25, p_convt_o2_weight, p_convt_o2_bias, [2, 2], [1, 1], [1, 1], True, [1, 1], 1);  add_25 = p_convt_o2_weight = p_convt_o2_bias = None\n",
       "            \n",
       "                     # File: /tmp/ipykernel_1459274/3926127313.py:185 in forward, code: output_class = F.softmax(y1, dim=1)\n",
       "                    softmax: \"f32[1, 3, 1984, 1472]\" = torch.ops.aten.softmax.int(convolution, 1);  convolution = None\n",
       "                    return (sub, softmax, convolution_1)\n",
       "            \n",
       "        Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_norm1_weight'), target='unet.convs.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_norm1_bias'), target='unet.convs.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_conv1_conv_weight'), target='unet.convs.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_conv1_conv_bias'), target='unet.convs.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_norm2_weight'), target='unet.convs.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_norm2_bias'), target='unet.convs.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_conv2_conv_weight'), target='unet.convs.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_conv2_conv_bias'), target='unet.convs.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_conv3_conv_weight'), target='unet.convs.0.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_0_conv3_conv_bias'), target='unet.convs.0.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_norm1_weight'), target='unet.convs.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_norm1_bias'), target='unet.convs.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_conv1_conv_weight'), target='unet.convs.1.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_conv1_conv_bias'), target='unet.convs.1.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_norm2_weight'), target='unet.convs.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_norm2_bias'), target='unet.convs.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_conv2_conv_weight'), target='unet.convs.1.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_conv2_conv_bias'), target='unet.convs.1.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_conv3_conv_weight'), target='unet.convs.1.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_1_conv3_conv_bias'), target='unet.convs.1.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_norm1_weight'), target='unet.convs.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_norm1_bias'), target='unet.convs.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_conv1_conv_weight'), target='unet.convs.2.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_conv1_conv_bias'), target='unet.convs.2.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_norm2_weight'), target='unet.convs.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_norm2_bias'), target='unet.convs.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_conv2_conv_weight'), target='unet.convs.2.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_conv2_conv_bias'), target='unet.convs.2.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_conv3_conv_weight'), target='unet.convs.2.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_2_conv3_conv_bias'), target='unet.convs.2.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_norm1_weight'), target='unet.convs.3.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_norm1_bias'), target='unet.convs.3.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_conv1_conv_weight'), target='unet.convs.3.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_conv1_conv_bias'), target='unet.convs.3.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_norm2_weight'), target='unet.convs.3.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_norm2_bias'), target='unet.convs.3.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_conv2_conv_weight'), target='unet.convs.3.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_conv2_conv_bias'), target='unet.convs.3.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_conv3_conv_weight'), target='unet.convs.3.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_3_conv3_conv_bias'), target='unet.convs.3.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_norm1_weight'), target='unet.convs.4.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_norm1_bias'), target='unet.convs.4.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_conv1_conv_weight'), target='unet.convs.4.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_conv1_conv_bias'), target='unet.convs.4.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_norm2_weight'), target='unet.convs.4.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_norm2_bias'), target='unet.convs.4.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_conv2_conv_weight'), target='unet.convs.4.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_conv2_conv_bias'), target='unet.convs.4.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_conv3_conv_weight'), target='unet.convs.4.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_4_conv3_conv_bias'), target='unet.convs.4.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_norm1_weight'), target='unet.convs_res.0.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_norm1_bias'), target='unet.convs_res.0.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_conv1_conv_weight'), target='unet.convs_res.0.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_conv1_conv_bias'), target='unet.convs_res.0.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_norm2_weight'), target='unet.convs_res.0.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_norm2_bias'), target='unet.convs_res.0.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_conv2_conv_weight'), target='unet.convs_res.0.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_0_layers_0_conv2_conv_bias'), target='unet.convs_res.0.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_norm1_weight'), target='unet.convs_res.1.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_norm1_bias'), target='unet.convs_res.1.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_conv1_conv_weight'), target='unet.convs_res.1.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_conv1_conv_bias'), target='unet.convs_res.1.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_norm2_weight'), target='unet.convs_res.1.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_norm2_bias'), target='unet.convs_res.1.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_conv2_conv_weight'), target='unet.convs_res.1.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_1_layers_0_conv2_conv_bias'), target='unet.convs_res.1.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_norm1_weight'), target='unet.convs_res.2.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_norm1_bias'), target='unet.convs_res.2.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_conv1_conv_weight'), target='unet.convs_res.2.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_conv1_conv_bias'), target='unet.convs_res.2.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_norm2_weight'), target='unet.convs_res.2.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_norm2_bias'), target='unet.convs_res.2.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_conv2_conv_weight'), target='unet.convs_res.2.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_2_layers_0_conv2_conv_bias'), target='unet.convs_res.2.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_norm1_weight'), target='unet.convs_res.3.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_norm1_bias'), target='unet.convs_res.3.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_conv1_conv_weight'), target='unet.convs_res.3.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_conv1_conv_bias'), target='unet.convs_res.3.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_norm2_weight'), target='unet.convs_res.3.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_norm2_bias'), target='unet.convs_res.3.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_conv2_conv_weight'), target='unet.convs_res.3.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_3_layers_0_conv2_conv_bias'), target='unet.convs_res.3.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_norm1_weight'), target='unet.convs_res.4.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_norm1_bias'), target='unet.convs_res.4.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_conv1_conv_weight'), target='unet.convs_res.4.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_conv1_conv_bias'), target='unet.convs_res.4.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_norm2_weight'), target='unet.convs_res.4.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_norm2_bias'), target='unet.convs_res.4.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_conv2_conv_weight'), target='unet.convs_res.4.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convs_res_4_layers_0_conv2_conv_bias'), target='unet.convs_res.4.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_norm1_weight'), target='unet.convts.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_norm1_bias'), target='unet.convts.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_conv1_conv_weight'), target='unet.convts.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_conv1_conv_bias'), target='unet.convts.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_norm2_weight'), target='unet.convts.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_norm2_bias'), target='unet.convts.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_conv2_conv_weight'), target='unet.convts.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_conv2_conv_bias'), target='unet.convts.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_conv3_conv_weight'), target='unet.convts.0.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_0_conv3_conv_bias'), target='unet.convts.0.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_norm1_weight'), target='unet.convts.1.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_norm1_bias'), target='unet.convts.1.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_conv1_conv_weight'), target='unet.convts.1.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_conv1_conv_bias'), target='unet.convts.1.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_norm2_weight'), target='unet.convts.1.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_norm2_bias'), target='unet.convts.1.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_conv2_conv_weight'), target='unet.convts.1.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_conv2_conv_bias'), target='unet.convts.1.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_conv3_conv_weight'), target='unet.convts.1.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_1_conv3_conv_bias'), target='unet.convts.1.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_norm1_weight'), target='unet.convts.2.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_norm1_bias'), target='unet.convts.2.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_conv1_conv_weight'), target='unet.convts.2.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_conv1_conv_bias'), target='unet.convts.2.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_norm2_weight'), target='unet.convts.2.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_norm2_bias'), target='unet.convts.2.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_conv2_conv_weight'), target='unet.convts.2.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_conv2_conv_bias'), target='unet.convts.2.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_conv3_conv_weight'), target='unet.convts.2.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_2_conv3_conv_bias'), target='unet.convts.2.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_norm1_weight'), target='unet.convts.3.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_norm1_bias'), target='unet.convts.3.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_conv1_conv_weight'), target='unet.convts.3.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_conv1_conv_bias'), target='unet.convts.3.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_norm2_weight'), target='unet.convts.3.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_norm2_bias'), target='unet.convts.3.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_conv2_conv_weight'), target='unet.convts.3.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_conv2_conv_bias'), target='unet.convts.3.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_conv3_conv_weight'), target='unet.convts.3.conv3.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_3_conv3_conv_bias'), target='unet.convts.3.conv3.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_norm1_weight'), target='unet.convts_res.0.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_norm1_bias'), target='unet.convts_res.0.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_conv1_conv_weight'), target='unet.convts_res.0.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_conv1_conv_bias'), target='unet.convts_res.0.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_norm2_weight'), target='unet.convts_res.0.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_norm2_bias'), target='unet.convts_res.0.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_conv2_conv_weight'), target='unet.convts_res.0.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_0_layers_0_conv2_conv_bias'), target='unet.convts_res.0.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_norm1_weight'), target='unet.convts_res.1.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_norm1_bias'), target='unet.convts_res.1.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_conv1_conv_weight'), target='unet.convts_res.1.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_conv1_conv_bias'), target='unet.convts_res.1.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_norm2_weight'), target='unet.convts_res.1.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_norm2_bias'), target='unet.convts_res.1.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_conv2_conv_weight'), target='unet.convts_res.1.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_1_layers_0_conv2_conv_bias'), target='unet.convts_res.1.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_norm1_weight'), target='unet.convts_res.2.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_norm1_bias'), target='unet.convts_res.2.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_conv1_conv_weight'), target='unet.convts_res.2.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_conv1_conv_bias'), target='unet.convts_res.2.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_norm2_weight'), target='unet.convts_res.2.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_norm2_bias'), target='unet.convts_res.2.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_conv2_conv_weight'), target='unet.convts_res.2.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_2_layers_0_conv2_conv_bias'), target='unet.convts_res.2.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_norm1_weight'), target='unet.convts_res.3.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_norm1_bias'), target='unet.convts_res.3.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_conv1_conv_weight'), target='unet.convts_res.3.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_conv1_conv_bias'), target='unet.convts_res.3.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_norm2_weight'), target='unet.convts_res.3.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_norm2_bias'), target='unet.convts_res.3.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_conv2_conv_weight'), target='unet.convts_res.3.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_convts_res_3_layers_0_conv2_conv_bias'), target='unet.convts_res.3.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_norm1_weight'), target='unet.links.0.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_norm1_bias'), target='unet.links.0.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_conv1_conv_weight'), target='unet.links.0.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_conv1_conv_bias'), target='unet.links.0.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_norm2_weight'), target='unet.links.0.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_norm2_bias'), target='unet.links.0.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_conv2_conv_weight'), target='unet.links.0.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_0_layers_0_conv2_conv_bias'), target='unet.links.0.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_norm1_weight'), target='unet.links.1.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_norm1_bias'), target='unet.links.1.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_conv1_conv_weight'), target='unet.links.1.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_conv1_conv_bias'), target='unet.links.1.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_norm2_weight'), target='unet.links.1.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_norm2_bias'), target='unet.links.1.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_conv2_conv_weight'), target='unet.links.1.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_1_layers_0_conv2_conv_bias'), target='unet.links.1.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_norm1_weight'), target='unet.links.2.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_norm1_bias'), target='unet.links.2.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_conv1_conv_weight'), target='unet.links.2.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_conv1_conv_bias'), target='unet.links.2.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_norm2_weight'), target='unet.links.2.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_norm2_bias'), target='unet.links.2.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_conv2_conv_weight'), target='unet.links.2.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_2_layers_0_conv2_conv_bias'), target='unet.links.2.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_norm1_weight'), target='unet.links.3.layers.0.norm1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_norm1_bias'), target='unet.links.3.layers.0.norm1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_conv1_conv_weight'), target='unet.links.3.layers.0.conv1.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_conv1_conv_bias'), target='unet.links.3.layers.0.conv1.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_norm2_weight'), target='unet.links.3.layers.0.norm2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_norm2_bias'), target='unet.links.3.layers.0.norm2.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_conv2_conv_weight'), target='unet.links.3.layers.0.conv2.conv.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_unet_links_3_layers_0_conv2_conv_bias'), target='unet.links.3.layers.0.conv2.conv.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_convt_o1_weight'), target='convT_o1.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_convt_o1_bias'), target='convT_o1.bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_convt_o2_weight'), target='convT_o2.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_convt_o2_bias'), target='convT_o2.bias', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_0_norm1_running_mean'), target='unet.convs.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_0_norm1_running_var'), target='unet.convs.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_0_norm1_num_batches_tracked'), target='unet.convs.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_0_norm2_running_mean'), target='unet.convs.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_0_norm2_running_var'), target='unet.convs.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_0_norm2_num_batches_tracked'), target='unet.convs.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_1_norm1_running_mean'), target='unet.convs.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_1_norm1_running_var'), target='unet.convs.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_1_norm1_num_batches_tracked'), target='unet.convs.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_1_norm2_running_mean'), target='unet.convs.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_1_norm2_running_var'), target='unet.convs.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_1_norm2_num_batches_tracked'), target='unet.convs.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_2_norm1_running_mean'), target='unet.convs.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_2_norm1_running_var'), target='unet.convs.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_2_norm1_num_batches_tracked'), target='unet.convs.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_2_norm2_running_mean'), target='unet.convs.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_2_norm2_running_var'), target='unet.convs.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_2_norm2_num_batches_tracked'), target='unet.convs.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_3_norm1_running_mean'), target='unet.convs.3.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_3_norm1_running_var'), target='unet.convs.3.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_3_norm1_num_batches_tracked'), target='unet.convs.3.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_3_norm2_running_mean'), target='unet.convs.3.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_3_norm2_running_var'), target='unet.convs.3.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_3_norm2_num_batches_tracked'), target='unet.convs.3.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_4_norm1_running_mean'), target='unet.convs.4.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_4_norm1_running_var'), target='unet.convs.4.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_4_norm1_num_batches_tracked'), target='unet.convs.4.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_4_norm2_running_mean'), target='unet.convs.4.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_4_norm2_running_var'), target='unet.convs.4.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_4_norm2_num_batches_tracked'), target='unet.convs.4.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_0_layers_0_norm1_running_mean'), target='unet.convs_res.0.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_0_layers_0_norm1_running_var'), target='unet.convs_res.0.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_0_layers_0_norm1_num_batches_tracked'), target='unet.convs_res.0.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_0_layers_0_norm2_running_mean'), target='unet.convs_res.0.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_0_layers_0_norm2_running_var'), target='unet.convs_res.0.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_0_layers_0_norm2_num_batches_tracked'), target='unet.convs_res.0.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_1_layers_0_norm1_running_mean'), target='unet.convs_res.1.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_1_layers_0_norm1_running_var'), target='unet.convs_res.1.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_1_layers_0_norm1_num_batches_tracked'), target='unet.convs_res.1.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_1_layers_0_norm2_running_mean'), target='unet.convs_res.1.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_1_layers_0_norm2_running_var'), target='unet.convs_res.1.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_1_layers_0_norm2_num_batches_tracked'), target='unet.convs_res.1.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_2_layers_0_norm1_running_mean'), target='unet.convs_res.2.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_2_layers_0_norm1_running_var'), target='unet.convs_res.2.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_2_layers_0_norm1_num_batches_tracked'), target='unet.convs_res.2.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_2_layers_0_norm2_running_mean'), target='unet.convs_res.2.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_2_layers_0_norm2_running_var'), target='unet.convs_res.2.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_2_layers_0_norm2_num_batches_tracked'), target='unet.convs_res.2.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_3_layers_0_norm1_running_mean'), target='unet.convs_res.3.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_3_layers_0_norm1_running_var'), target='unet.convs_res.3.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_3_layers_0_norm1_num_batches_tracked'), target='unet.convs_res.3.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_3_layers_0_norm2_running_mean'), target='unet.convs_res.3.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_3_layers_0_norm2_running_var'), target='unet.convs_res.3.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_3_layers_0_norm2_num_batches_tracked'), target='unet.convs_res.3.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_4_layers_0_norm1_running_mean'), target='unet.convs_res.4.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_4_layers_0_norm1_running_var'), target='unet.convs_res.4.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_4_layers_0_norm1_num_batches_tracked'), target='unet.convs_res.4.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_4_layers_0_norm2_running_mean'), target='unet.convs_res.4.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_4_layers_0_norm2_running_var'), target='unet.convs_res.4.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convs_res_4_layers_0_norm2_num_batches_tracked'), target='unet.convs_res.4.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_0_norm1_running_mean'), target='unet.convts.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_0_norm1_running_var'), target='unet.convts.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_0_norm1_num_batches_tracked'), target='unet.convts.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_0_norm2_running_mean'), target='unet.convts.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_0_norm2_running_var'), target='unet.convts.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_0_norm2_num_batches_tracked'), target='unet.convts.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_1_norm1_running_mean'), target='unet.convts.1.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_1_norm1_running_var'), target='unet.convts.1.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_1_norm1_num_batches_tracked'), target='unet.convts.1.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_1_norm2_running_mean'), target='unet.convts.1.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_1_norm2_running_var'), target='unet.convts.1.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_1_norm2_num_batches_tracked'), target='unet.convts.1.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_2_norm1_running_mean'), target='unet.convts.2.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_2_norm1_running_var'), target='unet.convts.2.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_2_norm1_num_batches_tracked'), target='unet.convts.2.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_2_norm2_running_mean'), target='unet.convts.2.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_2_norm2_running_var'), target='unet.convts.2.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_2_norm2_num_batches_tracked'), target='unet.convts.2.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_3_norm1_running_mean'), target='unet.convts.3.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_3_norm1_running_var'), target='unet.convts.3.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_3_norm1_num_batches_tracked'), target='unet.convts.3.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_3_norm2_running_mean'), target='unet.convts.3.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_3_norm2_running_var'), target='unet.convts.3.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_3_norm2_num_batches_tracked'), target='unet.convts.3.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_0_layers_0_norm1_running_mean'), target='unet.convts_res.0.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_0_layers_0_norm1_running_var'), target='unet.convts_res.0.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_0_layers_0_norm1_num_batches_tracked'), target='unet.convts_res.0.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_0_layers_0_norm2_running_mean'), target='unet.convts_res.0.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_0_layers_0_norm2_running_var'), target='unet.convts_res.0.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_0_layers_0_norm2_num_batches_tracked'), target='unet.convts_res.0.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_1_layers_0_norm1_running_mean'), target='unet.convts_res.1.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_1_layers_0_norm1_running_var'), target='unet.convts_res.1.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_1_layers_0_norm1_num_batches_tracked'), target='unet.convts_res.1.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_1_layers_0_norm2_running_mean'), target='unet.convts_res.1.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_1_layers_0_norm2_running_var'), target='unet.convts_res.1.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_1_layers_0_norm2_num_batches_tracked'), target='unet.convts_res.1.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_2_layers_0_norm1_running_mean'), target='unet.convts_res.2.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_2_layers_0_norm1_running_var'), target='unet.convts_res.2.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_2_layers_0_norm1_num_batches_tracked'), target='unet.convts_res.2.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_2_layers_0_norm2_running_mean'), target='unet.convts_res.2.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_2_layers_0_norm2_running_var'), target='unet.convts_res.2.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_2_layers_0_norm2_num_batches_tracked'), target='unet.convts_res.2.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_3_layers_0_norm1_running_mean'), target='unet.convts_res.3.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_3_layers_0_norm1_running_var'), target='unet.convts_res.3.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_3_layers_0_norm1_num_batches_tracked'), target='unet.convts_res.3.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_3_layers_0_norm2_running_mean'), target='unet.convts_res.3.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_3_layers_0_norm2_running_var'), target='unet.convts_res.3.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_convts_res_3_layers_0_norm2_num_batches_tracked'), target='unet.convts_res.3.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_0_layers_0_norm1_running_mean'), target='unet.links.0.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_0_layers_0_norm1_running_var'), target='unet.links.0.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_0_layers_0_norm1_num_batches_tracked'), target='unet.links.0.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_0_layers_0_norm2_running_mean'), target='unet.links.0.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_0_layers_0_norm2_running_var'), target='unet.links.0.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_0_layers_0_norm2_num_batches_tracked'), target='unet.links.0.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_1_layers_0_norm1_running_mean'), target='unet.links.1.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_1_layers_0_norm1_running_var'), target='unet.links.1.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_1_layers_0_norm1_num_batches_tracked'), target='unet.links.1.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_1_layers_0_norm2_running_mean'), target='unet.links.1.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_1_layers_0_norm2_running_var'), target='unet.links.1.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_1_layers_0_norm2_num_batches_tracked'), target='unet.links.1.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_2_layers_0_norm1_running_mean'), target='unet.links.2.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_2_layers_0_norm1_running_var'), target='unet.links.2.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_2_layers_0_norm1_num_batches_tracked'), target='unet.links.2.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_2_layers_0_norm2_running_mean'), target='unet.links.2.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_2_layers_0_norm2_running_var'), target='unet.links.2.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_2_layers_0_norm2_num_batches_tracked'), target='unet.links.2.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_3_layers_0_norm1_running_mean'), target='unet.links.3.layers.0.norm1.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_3_layers_0_norm1_running_var'), target='unet.links.3.layers.0.norm1.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_3_layers_0_norm1_num_batches_tracked'), target='unet.links.3.layers.0.norm1.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_3_layers_0_norm2_running_mean'), target='unet.links.3.layers.0.norm2.running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_3_layers_0_norm2_running_var'), target='unet.links.3.layers.0.norm2.running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_unet_links_3_layers_0_norm2_num_batches_tracked'), target='unet.links.3.layers.0.norm2.num_batches_tracked', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_INPUT_MUTATION: 6>, arg=TensorArgument(name='sub'), target='x'), OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='softmax'), target=None), OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='convolution_1'), target=None)])\n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet().cuda().eval()\n",
    "dummy_input = torch.randn(1, 1, 1984, 1472, device='cuda') \n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    'unet_dynamic.onnx',\n",
    "    input_names=['input'],\n",
    "    output_names=['output_class', 'output_pretil'],\n",
    "    #dynamic_axes=dynamic_axes,\n",
    "    opset_version=12,\n",
    "    verbose=True,\n",
    "    export_params=True,  # Store the trained parameter weights inside the model file\n",
    "    do_constant_folding=True,  # Whether to execute constant folding for optimization\n",
    "    dynamo=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-03-31 14:00:29.803127131 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_147'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803143129 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_144'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803145891 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_138'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803148221 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_135'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803150270 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_121'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803152383 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_115'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803154397 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_101'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803156437 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_98'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803158705 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_90'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803160782 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_87'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803162904 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_81'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803164899 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_78'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803167272 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_75'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803169502 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_70'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803171574 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_64'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803173657 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_61'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803175884 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_56'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803178051 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_53'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803180067 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_47'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803182200 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_42'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803184223 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_39'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803186421 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_28'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803189043 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_19'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803191072 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_141'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803193154 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_14'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803195289 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.3.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803197477 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.3.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803199706 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.2.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803201844 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.2.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803203997 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.1.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803206585 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.0.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803208965 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.3.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803211272 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.3.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803214283 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.2.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803216509 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.1.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803218641 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_5'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803220825 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_124'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803223002 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.1.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803225010 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_8'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803227733 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.0.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803229941 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_107'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803232459 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.0.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803234667 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.1.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803236840 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.3.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803239047 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.2.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803241568 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.1.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803244007 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_22'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803246119 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.4.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803249028 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts_res.2.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803251263 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.3.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803254611 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.1.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803256718 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.0.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803259803 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.2.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803262515 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_104'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803267343 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_11'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803270035 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803272716 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803275312 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_84'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803277558 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.2.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803279893 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_50'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803282160 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.3.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803284721 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.4.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803286918 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803289612 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_118'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803292821 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_67'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803295734 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.3.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803298034 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_130'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803300531 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.4.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803303974 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_95'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803306222 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.0.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803308244 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_110'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803310434 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_0'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803313519 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803316619 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_25'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803319325 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.4.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803321516 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_127'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803323624 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.2.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803326246 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.1.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803328422 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.2.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803331244 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.3.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803333512 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs.3.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803335738 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.1.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803337904 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_36'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803340125 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.1.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803342290 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.links.0.layers.0.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803344369 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convts.1.norm1.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803346599 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'unet.convs_res.2.layers.0.norm2.num_batches_tracked'. It is not used by any node and should be removed from the model.\u001b[m\n",
      "\u001b[0;93m2025-03-31 14:00:29.803348720 [W:onnxruntime:, graph.cc:4401 CleanUnusedInitializersAndNodeArgs] Removing initializer 'val_33'. It is not used by any node and should be removed from the model.\u001b[m\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 256 Expected: 1984\n index: 3 Got: 256 Expected: 1472\n Please fix either the inputs/outputs or the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Ejecutar el modelo ONNX\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Imprimir las salidas\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/workspace/pretiles/env/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:270\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    268\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n index: 2 Got: 256 Expected: 1984\n index: 3 Got: 256 Expected: 1472\n Please fix either the inputs/outputs or the model."
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo ONNX\n",
    "onnx_model_path = 'unet_dynamic.onnx'\n",
    "ort_session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Crear una entrada de prueba (igual que la que usaste para exportar el modelo)\n",
    "dummy_input = torch.randn(1, 1, 256, 256, device='cuda').cpu().numpy()\n",
    "\n",
    "# Ejecutar el modelo ONNX\n",
    "outputs = ort_session.run(None, {'input': dummy_input})\n",
    "\n",
    "# Imprimir las salidas\n",
    "print(\"Output class:\", outputs[0].shape)\n",
    "print(\"Output pretil:\", outputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956, 1464)\n",
      "[[[ 0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 5.4461293]\n",
      "  [-1.3409882]\n",
      "  [ 5.7214756]]\n",
      "\n",
      " [[-0.       ]\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  ...\n",
      "  [ 2.6519406]\n",
      "  [ 5.258803 ]\n",
      "  [ 2.5010145]]\n",
      "\n",
      " [[ 0.       ]\n",
      "  [ 0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 3.969255 ]\n",
      "  [ 0.918507 ]\n",
      "  [ 5.2430286]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]]\n",
      "\n",
      " [[ 0.       ]\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  ...\n",
      "  [-0.       ]\n",
      "  [-0.       ]\n",
      "  [-0.       ]]\n",
      "\n",
      " [[-0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]\n",
      "  ...\n",
      "  [ 0.       ]\n",
      "  [-0.       ]\n",
      "  [ 0.       ]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dem_file = 'dem3.npz'\n",
    "real_image = np.load(dem_file)['dem']\n",
    "print(real_image.shape)\n",
    "mask = np.load(dem_file)['mask']\n",
    "model = Unet()\n",
    "\n",
    "for i in range(100):\n",
    "    model.load_state_dict(torch.load(f'weigths/model_epoch_{i+1}.pth'))\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    testing(real_image, mask, i, 'cuda', 'testing/inference_dem_3')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
